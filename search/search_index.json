{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"Tandoor Recipes    The recipe manager that allows you to manage your ever growing collection of digital recipes. <p> Website \u2022 Installation \u2022 Docs \u2022 Demo \u2022 Discord </p> <p></p>"},{"location":"#core-features","title":"Core Features","text":"<ul> <li>\ud83e\udd57 Manage your recipes with a fast and intuitive editor</li> <li>\ud83d\udcc6 Plan multiple meals for each day</li> <li>\ud83d\uded2 Shopping lists via the meal plan or straight from recipes</li> <li>\ud83d\udcda Cookbooks collect recipes into books</li> <li>\ud83d\udc6a Share and collaborate on recipes with friends and family</li> </ul>"},{"location":"#made-by-and-for-power-users","title":"Made by and for power users","text":"<ul> <li>\ud83d\udd0d Powerful &amp; customizable search with fulltext support and TrigramSimilarity</li> <li>\ud83c\udff7\ufe0f Create and search for tags, assign them in batch to all files matching certain filters</li> <li>\u2194\ufe0f Quickly merge and rename ingredients, tags and units </li> <li>\ud83d\udce5\ufe0f Import recipes from thousands of websites supporting ld+json or microdata</li> <li>\u2797 Support for fractions or decimals</li> <li>\ud83d\udc33 Easy setup with Docker and included examples for Kubernetes, Unraid and Synology</li> <li>\ud83c\udfa8 Customize your interface with themes</li> <li>\ud83d\udce6 Sync files with Dropbox and Nextcloud</li> </ul>"},{"location":"#all-the-must-haves","title":"All the must haves","text":"<ul> <li>\ud83d\udcf1  Optimized for use on mobile devices</li> <li>\ud83c\udf0d Localized in many languages thanks to the awesome community</li> <li>\ud83d\udce5\ufe0f Import your collection from many other recipe managers</li> <li>\u2795 Many more like recipe scaling, image compression, printing views and supermarkets</li> </ul> <p>This application is meant for people with a collection of recipes they want to share with family and friends or simply store them in a nicely organized way. A basic permission system exists but this application is not meant to be run as  a public page.</p>"},{"location":"#your-feedback","title":"Your Feedback","text":"<p>Share some information on how you use Tandoor to help me improve the application Google Survey</p>"},{"location":"#get-in-touch","title":"Get in touch","text":"Discord We have a public Discord server that anyone can join. This is where all our developers and contributors hang out and where we make announcements Twitter You can follow our Twitter account to get updates on new features or releases"},{"location":"#roadmap","title":"Roadmap","text":"<p>This application has been under rapid development over the last year. During this time I have learnt a lot and added tons of features, I have also moved to some new technologies like Vue.js. This has led to some great features but has left the Quality unsatisfactory in regard to the details and technical implementation.</p> <p>So in addition to the new Features and Ideas which can always be found in the Issues &amp; Milestones there are some greater overall goals for the future (in no particular order)</p> <ul> <li>Improve the UI! The Design is inconsistent and many pages work but don't look great. This needs to change.</li> <li>I strongly believe in Open Data and Systems. Thus adding importers and exporters for all relevant other recipe management systems is something i really want to do.</li> <li>Move all Javascript Libraries to a packet manager and clean up some of the mess I made in the early days</li> <li>Improve Test coverage and also the individual tests themselves</li> <li>Improve the documentation for all features and aspects of this project and add some application integrated help</li> </ul>"},{"location":"#about","title":"About","text":"<p>This application has originally been developed to index, tag and search my collection of digital (PDF) recipes. Over the time tons of features have been added making this the most comprehensive recipe management system. </p> <p>I am just a single developer with many other interests and obligations so development and support might be slow at times,  but I try my best to constantly improve this application.</p> <p>If you have any wishes, feature requests, problems or ideas feel free to open an issue on GitHub.</p>"},{"location":"contribute/","title":"Contributing","text":"<p>If you like this application and want it to improve, feel free to contribute to its development.</p> <p>Contribution List</p> <p>If you help bring this project forward you deserve to be credited for it. Feel free to add yourself to <code>CONTRIBUTERS.md</code> or message me to add you if you have contributed anything.</p>"},{"location":"contribute/#issues","title":"Issues","text":"<p>The most basic but also very important way of contributing is reporting issues and commenting on ideas and feature requests over at GitHub issues.</p> <p>Without feedback improvement can't happen, so don't hesitate to say what you want to say.</p>"},{"location":"contribute/#contributing-code","title":"Contributing Code","text":"<p>If you want to contribute bug fixes or small tweaks then your pull requests are always welcome!</p> <p>Discuss First!</p> <p>If you want to contribute larger features that introduce more complexity to the project please make sure to first submit a technical description outlining what and how you want to do it.  This allows me and the community to give feedback and manage the complexity of the overall  application. If you don't do this please don't be mad if I reject your PR</p> <p>Info</p> <p>The dev setup is a little messy as this application combines the best (at least in my opinion) of both Django and Vue.js.</p>"},{"location":"contribute/#django","title":"Django","text":"<p>This application is developed using the Django framework for Python. They have excellent  documentation on how to get started, so I will only give you the basics here.</p> <ol> <li>Clone this repository wherever you like and install the Python language for your OS (I recommend using version 3.10 or above).</li> <li>Open it in your favorite editor/IDE (e.g. PyCharm).     a. If you want, create a virtual environment for all your packages.</li> <li>Install all required packages: <code>pip install -r requirements.txt</code>.</li> <li>Run the migrations: <code>python manage.py migrate</code>.</li> <li>Start the development server: <code>python manage.py runserver</code>.</li> </ol> <p>There is no need to set any environment variables. By default, a simple SQLite database is used and all settings are populated from default values.</p>"},{"location":"contribute/#vuejs","title":"Vue.js","text":"<p>Most new frontend pages are build using Vue.js. </p> <p>In order to work on these pages, you will have to install a Javascript package manager of your choice. The following examples use yarn.</p> <p>In the <code>vue</code> folder run <code>yarn install</code> to install the dependencies. After that you can use <code>yarn serve</code> to start the development server, and proceed to test your changes. If you do not wish to work on those pages, but instead want the application to work properly during  development, run <code>yarn build</code> to build the frontend pages once. </p>"},{"location":"contribute/#api-client","title":"API Client","text":"<p>The API Client is generated automatically from the OpenAPI interface provided by the Django REST framework. For this openapi-generator is used.</p> <p>Install it using your desired setup method. (For example, using <code>npm install @openapitools/openapi-generator-cli -g</code>.)</p> <p>Navigate to <code>vue/src/utils/openapi</code>.</p> <p>Generate the schema using <code>openapi-generator-cli generate -g typescript-axios -i http://127.0.0.1:8000/openapi/</code>. (Replace your dev server url if required.)</p>"},{"location":"contribute/#contribute-documentation","title":"Contribute Documentation","text":"<p>The documentation is built from the markdown files in the docs folder of the GitHub repository.</p> <p>In order to contribute to the documentation, you can fork the repository and edit the markdown files in the browser.</p> <p>Now install mkdocs and dependencies: <code>pip install mkdocs-material mkdocs-include-markdown-plugin</code>.</p> <p>If you want to test the documentation, locally run <code>mkdocs serve</code> from the project root.</p>"},{"location":"contribute/#contribute-translations","title":"Contribute Translations","text":"<p>If you know any foreign languages that the project has not been completely translated to yet, feel free to contribute translations.</p> <p>Translations are managed on translate.tandoor.dev, a self hosted instance of Weblate.</p> <p>You can simply register an account and then follow these steps to add translations:</p> <ol> <li>After registering, you are asked to select your languages. This is optional but allows weblate to only show you relevant translations.</li> <li>In the navigation click on <code>Projects</code> and then <code>Browse all projects</code>.</li> <li>Select Tandoor and on the top-right hand corner, select <code>Watch project Tandoor</code> (click on <code>Not watching</code>).</li> <li>Go back to the dashboard. It now shows you the relevant translations for your languages. Click on the pencil icon to get started.</li> </ol> <p>Creating a new language</p> <p>To create a new language you must first select Tandoor (the project) and then a component. Here you will have the option to add the language. Afterwards you can also simply add it to the other components as well. Once a new language is (partially) finished let me know on GitHub so I can add it to the language-switcher in Tandoor itself. </p> <p>There is also a lot of documentation available from Weblate directly.</p> <p></p> <p>It is also possible to provide the translations directly by creating a new language  using <code>manage.py makemessages -l &lt;language_code&gt; -i venv</code>. Once finished, simply open a PR with the changed files. This sometimes causes issues merging  with weblate, so I would prefer the use of weblate.</p>"},{"location":"faq/","title":"FAQ","text":"<p>There are several questions and issues that come up from time to time, here are some answers: please note that the existence of some questions is due the application not being perfect in some parts.  Many of those shortcomings are planned to be fixed in future release but simply could not be addressed yet due to time limits.</p>"},{"location":"faq/#is-there-a-tandoor-app","title":"Is there a Tandoor app?","text":"<p>Tandoor can be installed as a progressive web app (PWA) on mobile and desktop devices. The PWA stores recently accessed recipes locally for offline use.</p>"},{"location":"faq/#mobile-browsers","title":"Mobile browsers","text":""},{"location":"faq/#safari-iphoneipad","title":"Safari (iPhone/iPad)","text":"<p>Open Tandoor, click Safari's share button, select <code>Add to Home Screen</code></p>"},{"location":"faq/#chromechromium","title":"Chrome/Chromium","text":"<p>Open Tandoor, click the <code>add Tandoor to the home screen</code> message that pops up at the bottom of the screen</p>"},{"location":"faq/#desktop-browsers","title":"Desktop browsers","text":""},{"location":"faq/#google-chrome","title":"Google Chrome","text":"<p>Open Tandoor, open the menu behind the three vertical dots at the top right, select <code>Install Tandoor Recipes...</code></p>"},{"location":"faq/#microsoft-edge","title":"Microsoft Edge","text":"<p>Open Tandoor, open the menu behind the three horizontal dots at the top right, select <code>Apps &gt; Install Tandoor Recipes</code></p>"},{"location":"faq/#why-is-tandoor-not-working-correctly","title":"Why is Tandoor not working correctly?","text":"<p>If you just set up your Tandoor instance and you're having issues like;</p> <ul> <li>Links not working</li> <li>CSRF errors</li> <li>CORS errors</li> <li>No recipes are loading</li> </ul> <p>then make sure you have set all required headers in your reverse proxy correctly. If that doesn't fix it, you can also refer to the appropriate sub section in the reverse proxy documentation and verify your general webserver configuration.</p>"},{"location":"faq/#why-am-i-getting-csrf-errors","title":"Why am I getting CSRF Errors?","text":"<p>If you are getting CSRF Errors this is most likely due to a reverse proxy not passing the correct headers.</p> <p>If you are using swag by linuxserver you might need <code>proxy_set_header X-Forwarded-Proto $scheme;</code> in your nginx config. If you are using a plain ngix you might need <code>proxy_set_header Host $http_host;</code>.</p> <p>Further discussions can be found in this Issue #518</p>"},{"location":"faq/#why-are-images-not-loading","title":"Why are images not loading?","text":"<p>If images are not loading this might be related to the same issue as the CSRF errors (see above).  A discussion about that can be found at Issue #452</p> <p>The other common issue is that the recommended nginx container is removed from the deployment stack.  If removed, the nginx webserver needs to be replaced by something else that servers the /mediafiles/ directory or  <code>GUNICORN_MEDIA</code> needs to be enabled to allow media serving by the application container itself.</p>"},{"location":"faq/#why-does-the-textmarkdown-preview-look-different-than-the-final-recipe","title":"Why does the Text/Markdown preview look different than the final recipe?","text":"<p>Tandoor has always rendered the recipe instructions markdown on the server. This also allows tandoor to implement things like ingredient templating and scaling in text. To make editing easier a markdown editor was added to the frontend with integrated preview as a temporary solution. Since the markdown editor uses a different  specification than the server the preview is different to the final result. It is planned to improve this in the future. </p> <p>The markdown renderer follows this markdown specification https://daringfireball.net/projects/markdown/</p>"},{"location":"faq/#why-is-tandoor-not-working-on-my-raspberry-pi","title":"Why is Tandoor not working on my Raspberry Pi?","text":"<p>Please refer to here.</p>"},{"location":"faq/#how-can-i-create-users","title":"How can I create users?","text":"<p>To create a new user click on your name (top right corner) and select 'space settings'. Click create listed below invites.</p> <p>It is not possible to create users through the admin because users must be assigned a default group and space.</p> <p>To change a user's space you need to go to the admin and select User Infos. </p> <p>If you use an external auth provider or proxy authentication make sure to specify a default group and space in the  environment configuration.</p>"},{"location":"faq/#what-are-spaces","title":"What are spaces?","text":"<p>Spaces are is a type of feature used to separate one installation of Tandoor into several parts.  In technical terms it is a multi-tenant system.</p> <p>You can compare a space to something like google drive or dropbox.  There is only one installation of the Dropbox system, but it handles multiple users without them noticing each other. For Tandoor that means all people that work together on one recipe collection can be in one space.  If you want to host the collection of your friends, family, or neighbor you can create a separate space for them (through the admin interface).</p> <p>Sharing between spaces is currently not possible but is planned for future releases.</p>"},{"location":"faq/#how-can-i-reset-passwords","title":"How can I reset passwords?","text":"<p>To reset a lost password if access to the container is lost you need to:</p> <ol> <li>execute into the container using <code>docker-compose exec web_recipes sh</code></li> <li>activate the virtual environment <code>source venv/bin/activate</code></li> <li>run <code>python manage.py changepassword &lt;username&gt;</code> and follow the steps shown.</li> </ol>"},{"location":"faq/#how-can-i-add-an-admin-user","title":"How can I add an admin user?","text":"<p>To create a superuser you need to </p> <ol> <li>execute into the container using <code>docker-compose exec web_recipes sh</code></li> <li>activate the virtual environment <code>source venv/bin/activate</code></li> <li>run <code>python manage.py createsuperuser</code> and follow the steps shown.</li> </ol>"},{"location":"faq/#why-cant-i-get-support-for-my-manual-setup","title":"Why cant I get support for my manual setup?","text":"<p>Even tough I would love to help everyone get tandoor up and running I have only so much time  that I can spend on this project besides work, family and other life things.  Due to the countless problems that can occur when manually installing I simply do not have  the time to help solving each one. </p> <p>You can install Tandoor manually but please do not expect me or anyone to help you with that.  As a general advice: If you do it manually do NOT change anything at first and slowly work yourself  to your dream setup.</p>"},{"location":"features/authentication/","title":"Authentication","text":"<p>Besides the normal django username and password authentication this application supports multiple  methods of central account management and authentication.</p>"},{"location":"features/authentication/#allauth","title":"Allauth","text":"<p>Django Allauth is an awesome project that  allows you to use a huge number of different authentication providers.</p> <p>They basically explain everything in their documentation, but the following is a short overview on how to get started.</p> <p>Public Providers</p> <p>If you choose Google, Github or any other publicly available service as your authentication provider anyone with an account on that site can create an account on your installation. A new account does not have any permission but it is still not recommended to give public access to  your installation. </p> <p>Choose a provider from the list and install it using the environment variable <code>SOCIAL_PROVIDERS</code> as shown in the example below.</p> <pre><code>SOCIAL_PROVIDERS=allauth.socialaccount.providers.github,allauth.socialaccount.providers.nextcloud\n</code></pre> <p>Formatting</p> <p>The exact formatting is important so make sure to follow the steps explained here!</p> <p>Depending on your authentication provider you might need to configure it.  This needs to be done through the settings system. To make the system flexible (allow multiple providers) and to  not require another file to be mounted into the container the configuration ins done through a single environment variable. The downside of this approach is that the configuration needs to be put into a single line as environment files loaded by docker compose don't support multiple lines for a single variable.</p> <p>Take the example configuration from the allauth docs, fill in your settings and then inline the whole object  (you can use a service like www.freeformatter.com for formatting). Assign it to the additional <code>SOCIALACCOUNT_PROVIDERS</code> variable.</p> <pre><code>SOCIALACCOUNT_PROVIDERS={\"nextcloud\":{\"SERVER\":\"https://nextcloud.example.org\"}}\n</code></pre> <p>Improvements ?</p> <p>There are most likely ways to achieve the same goal but with a cleaner or simpler system. If you know such a way feel free to let me know.</p> <p>After that, use your superuser account to configure your authentication backend. Open the admin page and do the following</p> <ol> <li>Select <code>Sites</code> and edit the default site with the URL of your installation (or create a new).</li> <li>Create a new <code>Social Application</code> with the required information as stated in the provider documentation of allauth.</li> <li>Make sure to add your site to the list of available sites</li> </ol> <p>Now the provider is configured and you should be able to sign up and sign in using the provider. Use the superuser account to grant permissions to the newly created users.</p> <p>WIP</p> <p>I do not have a ton of experience with using various single signon providers and also cannot test all of them. If you have any Feedback or issues let me know.</p>"},{"location":"features/authentication/#third-party-authentication-example","title":"Third-party authentication example","text":"<p>Keycloak is a popular IAM solution and integration is straight forward thanks to Django Allauth. This example can also be used as reference for other third-party authentication solutions, as documented by Allauth.</p> <p>At Keycloak, create a new client and assign a <code>Client-ID</code>, this client comes with a <code>Secret-Key</code>. Both values are required later on. Make sure to define the correct Redirection-URL for the service, for example <code>https://tandoor.example.com/*</code>. Depending on your Keycloak setup, you need to assign roles and groups to grant access to the service.</p> <p>To enable Keycloak as a sign in option, set those variables to define the social provider and specify its configuration: <pre><code>SOCIAL_PROVIDERS=allauth.socialaccount.providers.keycloak\nSOCIALACCOUNT_PROVIDERS='{ \"keycloak\": { \"KEYCLOAK_URL\": \"https://auth.example.com/\", \"KEYCLOAK_REALM\": \"master\" } }'\n</code></pre></p> <ol> <li>Restart the service, login as superuser and open the <code>Admin</code> page.</li> <li>Make sure that the correct <code>Domain Name</code> is defined at <code>Sites</code>.</li> <li>Select <code>Social Application</code> and chose <code>Keycloak</code> from the provider list.</li> <li>Provide an arbitrary name for your authentication provider, and enter the <code>Client-ID</code> and <code>Secret Key</code> values obtained from Keycloak earlier.</li> <li>Make sure to add your <code>Site</code> to the list of available sites and save the new <code>Social Application</code>.</li> </ol> <p>You are now able to sign in using Keycloak.</p>"},{"location":"features/authentication/#linking-accounts","title":"Linking accounts","text":"<p>To link an account to an already existing normal user go to the settings page of the user and link it.  Here you can also unlink your account if you no longer want to use a social login method.</p>"},{"location":"features/authentication/#ldap","title":"LDAP","text":"<p>LDAP authentication can be enabled in the <code>.env</code> file by setting <code>LDAP_AUTH=1</code>. If set, users listed in the LDAP instance will be able to sign in without signing up. These variables must be set to configure the connection to the LDAP instance: <pre><code>AUTH_LDAP_SERVER_URI=ldap://ldap.example.org:389\nAUTH_LDAP_BIND_DN=uid=admin,ou=users,dc=example,dc=org\nAUTH_LDAP_BIND_PASSWORD=adminpassword\nAUTH_LDAP_USER_SEARCH_BASE_DN=ou=users,dc=example,dc=org\n</code></pre> Additional optional variables: <pre><code>AUTH_LDAP_USER_SEARCH_FILTER_STR=(uid=%(user)s)\nAUTH_LDAP_USER_ATTR_MAP={'first_name': 'givenName', 'last_name': 'sn', 'email': 'mail'}\nAUTH_LDAP_ALWAYS_UPDATE_USER=1\nAUTH_LDAP_CACHE_TIMEOUT=3600\nAUTH_LDAP_START_TLS=1\nAUTH_LDAP_TLS_CACERTFILE=/etc/ssl/certs/own-ca.pem\n</code></pre></p>"},{"location":"features/authentication/#reverse-proxy-authentication","title":"Reverse Proxy Authentication","text":"<p>Community Contributed Tutorial</p> <p>This tutorial was provided by a community member. Since I do not use reverse proxy authentication, I cannot provide any  assistance should you choose to use this authentication method.</p> <p>In order use proxy authentication you will need to:</p> <ol> <li>Set <code>REVERSE_PROXY_AUTH=1</code> in the <code>.env</code> file</li> <li>Update your nginx configuration file</li> </ol> <p>Using any of the examples above will automatically generate a configuration file inside a docker volume. Use <code>docker volume inspect recipes_nginx</code> to find out where your volume is stored.</p> <p>Configuration File Volume</p> <p>The nginx config volume is generated when the container is first run. You can change the volume to a bind mount in the warning <code>docker-compose.yml</code>, but then you will need to manually create it. See section <code>Volumes vs Bind Mounts</code> below for more information.</p> <p>The following example shows a configuration for Authelia:</p> <pre><code>server {\n  listen 80;\n  server_name localhost;\n\n  client_max_body_size 16M;\n\n  # serve static files\n  location /static/ {\n    alias /static/;\n  }\n  # serve media files\n  location /media/ {\n    alias /media/;\n  }\n\n  # Authelia endpoint for authentication requests\n  include /config/nginx/auth.conf;\n\n  # pass requests for dynamic content to gunicorn\n  location / {\n    proxy_set_header Host $host;\n    proxy_pass http://web_recipes:8080;\n\n    # Ensure Authelia is specifically required for this endpoint\n    # This line is important as it will return a 401 error if the user doesn't have access\n    include /config/nginx/authelia.conf;\n\n    auth_request_set $user $upstream_http_remote_user;\n    proxy_set_header REMOTE-USER $user;\n  }\n\n  # Required to allow user to logout of authentication from within Recipes\n  # Ensure the &lt;auth_endpoint&gt; below is changed to actual the authentication url\n  location /accounts/logout/ {\n    return 301 http://&lt;auth_endpoint&gt;/logout;\n  }\n}\n</code></pre> <p>Please refer to the appropriate documentation on how to setup the reverse proxy, authentication, and networks.</p> <p>Ensure users have been configured for Authelia, and that the endpoint recipes is pointed to is protected but available.</p> <p>There is a good guide to the other additional files that need to be added to your nginx set up at the Authelia Docs.</p> <p>Remember to add the appropriate environment variables to <code>.env</code> file (example for nginx proxy):</p> <pre><code>VIRTUAL_HOST=\nLETSENCRYPT_HOST=\nLETSENCRYPT_EMAIL=\nPROXY_HEADER=\n</code></pre>"},{"location":"features/automation/","title":"Automation","text":"<p>Warning</p> <p>Automations are currently in a beta stage. They work pretty stable but if I encounter any  issues while working on them, I might change how they work breaking existing automations. I will try to avoid this and am pretty confident it won't happen.</p> <p>Automations allow Tandoor to automatically perform certain tasks, especially when importing recipes, that  would otherwise have to be done manually. Currently, the following automations are supported.</p>"},{"location":"features/automation/#unit-food-keyword-alias","title":"Unit, Food, Keyword Alias","text":"<p>Foods, Units and Keywords can have automations that automatically replace them with another object to allow aliasing them. </p> <p>This helps to add consistency to the naming of objects, for example to always use the singular form for the main name if a plural form is configured. </p> <p>These automations are best created by dragging and dropping Foods, Units or Keywords in their respective  views and creating the automation there. </p> <p>You can also create them manually by setting the following - Parameter 1: name of food/unit/keyword to match - Parameter 2: name of food/unit/keyword to replace matched food with</p> <p>These rules are processed whenever you are importing recipes from websites or other apps and when using the simple ingredient input (shopping, recipe editor, ...).</p>"},{"location":"features/automation/#description-replace","title":"Description Replace","text":"<p>This automation is a bit more complicated than the alis rules. It is run when importing a recipe from a website.</p> <p>It uses Regular Expressions (RegEx) to determine if a description should be altered, what exactly to remove and what to replace it with. </p> <ul> <li>Parameter 1: pattern of which sites to match (e.g. <code>.*.chefkoch.de.*</code>, <code>.*</code>)</li> <li>Parameter 2: pattern of what to replace (e.g. <code>.*</code>)</li> <li>Parameter 3: value to replace matched occurrence of parameter 2 with. Only one occurrence of the pattern is replaced.</li> </ul> <p>To replace the description the python re.sub function is used like this <code>re.sub(&lt;parameter 2&gt;, &lt;parameter 2&gt;, &lt;descriotion&gt;, count=1)</code></p> <p>To test out your patterns and learn about RegEx you can use regexr.com</p> <p>Info</p> <p>In order to prevent denial of service attacks on the RegEx engine the number of replace automations  and the length of the inputs that are processed are limited. Those limits should never be reached during normal usage. </p>"},{"location":"features/automation/#instruction-replace","title":"Instruction Replace","text":"<p>This works just like the Description Replace automation but runs against all instruction texts in all steps of a recipe during import. </p> <p>Also instead of just replacing a single occurrence of the matched pattern it will replace all.</p>"},{"location":"features/automation/#order","title":"Order","text":"<p>If the Automation type allows for more than one rule to be executed (for example description replace)  the rules are processed in ascending order (ordered by the order property of the automation).  The default order is always 1000 to make it easier to add automations before and after other automations. </p> <p>Example: 1. Rule ABC (order 1000) replaces <code>everything</code> with <code>abc</code> 2. Rule DEF (order 2000) replaces <code>everything</code> with <code>def</code> 3. Rule XYZ (order 500) replaces <code>everything</code> with <code>xyz</code></p> <p>After processing rules XYZ, then ABC and then DEF the description will have the value <code>def</code></p>"},{"location":"features/external_recipes/","title":"Storages and Sync","text":"<p>The original intend of this application was to provide a search interface to my large collection of PDF scans of recipes. This feature is now called External recipes.</p> <p>Info</p> <p>Internal recipes are stored in a structured manner inside the database. They can be displayed using the standardized interface and support features like shopping lists, scaling and steps. External recipes are basically files that are displayed within the interface. The benefit is that you can quickly import all your old recipes and convert them one by one.</p> <p>To use external recipes you will first need to configure a storage source. After that a synced path can be created. Lastly you will need to sync with the external path and import recipes you desire.</p>"},{"location":"features/external_recipes/#storage","title":"Storage","text":"<p>Danger</p> <p>In order for this application to retrieve data from external providers it needs to store authentication information. Please use read only/separate accounts or app passwords wherever possible. There are better ways to do this but they are currently not implemented</p> <p>A <code>Storage Backend</code> is a remote storage location where files are read from. To add a new backend click on <code>username &gt;&gt; External Recipes &gt;&gt; Manage External Storage &gt;&gt; the + next to Storage Backend List</code>.  There click the plus button.</p> <p>The basic configuration is the same for all providers. </p> Field Value Name Your identifier for this storage source, can be everything you want. Method The desired method. <p>Success</p> <p>Only the providers listed below are currently implemented. If you need anything else feel free to open an issue or pull request.</p>"},{"location":"features/external_recipes/#local","title":"Local","text":"<p>Info</p> <p>There is currently no way to upload files through the webinterface. This is a feature that might be added later.</p> <p>The local provider does not need any configuration (username, password, token or URL). For the monitor you will need to define a valid path on your host system. (Path)  The Path depends on your setup and can be both relative and absolute. </p> <p>Volume</p> <p>By default no data other than the mediafiles and the database is persisted. If you use the local provider make sure to mount the path you choose to monitor to your host system in order to keep it persistent.</p>"},{"location":"features/external_recipes/#docker","title":"Docker","text":"<p>If you use docker the default directory is <code>/opt/recipes/</code>. add <pre><code>      - ./externalfiles:/opt/recipes/externalfiles\n</code></pre> to your docker-compose.yml file under the <code>web_recipes &gt;&gt; volumes</code> section. This will create a folder in your docker directory named <code>externalfiles</code> under which you could choose to store external pdfs (you could of course store them anywhere, just change <code>./externalfiles</code> to your preferred location). save the docker-compose.yml and restart your docker container.</p>"},{"location":"features/external_recipes/#dropbox","title":"Dropbox","text":"Field Value Username Dropbox username Token Dropbox API Token. Can be found here"},{"location":"features/external_recipes/#nextcloud","title":"Nextcloud","text":"<p>Path</p> <p>It appears that the correct webdav path varies from installation to installation (for whatever reason). In the Nextcloud webinterface click the <code>Settings</code> button in the bottom left corner, there your WebDav Url will be displayed.</p> Field Value Username Nextcloud username Password Nextcloud app password Url Nextcloud Server URL (e.g. <code>https://cloud.mydomain.com</code>) Path (optional) webdav path (e.g. <code>/remote.php/dav/files/vabene1111</code>). If no path is supplied <code>/remote.php/dav/files/</code> plus your username will be used."},{"location":"features/external_recipes/#adding-external-recipes","title":"Adding External Recipes","text":"<p>To add a new path from your Storage backend to the sync list, go to <code>username &gt;&gt; External Recipes</code> and  select the storage backend you want to use. Then enter the path you want to monitor starting at the storage root (e.g. <code>/Folder/RecipesFolder</code>, or `/opt/recipes/externalfiles' in the docker example above) and save it.</p>"},{"location":"features/external_recipes/#syncing-data","title":"Syncing Data","text":"<p>To sync the recipes app with the storage backends press <code>Sync now</code> under <code>username &gt;&gt; External Recipes</code></p>"},{"location":"features/external_recipes/#discovered-recipes","title":"Discovered Recipes","text":"<p>All files found by the sync can be found under <code>Manage Data &gt;&gt; Discovered recipes</code>.  There you can either import all at once without modifying them or import one by one, adding tags while importing.</p>"},{"location":"features/import_export/","title":"Import/Export","text":"<p>This application features a very versatile import and export feature in order  to offer the best experience possible and allow you to freely choose where your data goes.</p> <p>WIP</p> <p>The Module is relatively new. There is a known issue with Timeouts on large exports. A fix is being developed and will likely be released with the next version.</p> <p>The Module is built with maximum flexibility and expandability in mind and allows to easily add new integrations to allow you to both import and export your recipes into whatever format you desire.</p> <p>Feel like there is an important integration missing? Just take a look at the integration issues or open a new one if your favorite one is missing.</p> <p>Export</p> <p>I strongly believe in everyone's right to use their data as they please and therefore want to give you  the best possible flexibility with your recipes. That said for most of the people getting this application running with their recipes is the biggest priority. Because of this importing as many formats as possible is prioritized over exporting. Exporter for the different formats will follow over time.</p> <p>Overview of the capabilities of the different integrations.</p> Integration Import Export Images Default \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Nextcloud \u2714\ufe0f \u231a \u2714\ufe0f Mealie \u2714\ufe0f \u231a \u2714\ufe0f Chowdown \u2714\ufe0f \u231a \u2714\ufe0f Safron \u2714\ufe0f \u2714\ufe0f \u274c Paprika \u2714\ufe0f \u231a \u2714\ufe0f ChefTap \u2714\ufe0f \u274c \u274c Pepperplate \u2714\ufe0f \u231a \u274c RecipeSage \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Rezeptsuite.de \u2714\ufe0f \u274c \u2714\ufe0f Domestica \u2714\ufe0f \u231a \u2714\ufe0f MealMaster \u2714\ufe0f \u274c \u274c RezKonv \u2714\ufe0f \u274c \u274c OpenEats \u2714\ufe0f \u274c \u231a Plantoeat \u2714\ufe0f \u274c \u2714 CookBookApp \u2714\ufe0f \u231a \u2714\ufe0f CopyMeThat \u2714\ufe0f \u274c \u2714\ufe0f Melarecipes \u2714\ufe0f \u231a \u2714\ufe0f Cookmate \u2714\ufe0f \u231a \u2714\ufe0f PDF (experimental) \u231a\ufe0f \u2714\ufe0f \u2714\ufe0f <p>\u2714\ufe0f = implemented, \u274c = not implemented and not possible/planned, \u231a = not yet implemented</p>"},{"location":"features/import_export/#default","title":"Default","text":"<p>The default integration is the built in (and preferred) way to import and export recipes. It is maintained with new fields added and contains all data to transfer your recipes from one installation to another.</p> <p>It is also one of the few recipe formats that is actually structured in a way that allows for  easy machine readability if you want to use the data for any other purpose. </p>"},{"location":"features/import_export/#recipesage","title":"RecipeSage","text":"<p>Go to Settings &gt; Export Recipe Data and select <code>EXPORT AS JSON-LD (BEST)</code>. Then simply upload the exported file  to Tandoor.</p> <p>The RecipeSage integration also allows exporting. To migrate from Tandoor to RecipeSage simply export with Recipe Sage  selected and import the json file in RecipeSage. Images are currently not supported for exporting.</p>"},{"location":"features/import_export/#domestica","title":"Domestica","text":"<p>Go to Import/Export and select <code>Export Recipes</code>. Then simply upload the exported file  to Tandoor.</p>"},{"location":"features/import_export/#nextcloud","title":"Nextcloud","text":"<p>Importing recipes from Nextcloud cookbook is very easy and since Nextcloud Cookbook provides nice, standardized and  structured information most of your recipe is going to be intact.</p> <p>Follow these steps to import your recipes</p> <ol> <li>Go to your Nextcloud Webinterface</li> <li>Open the <code>Recipes</code> folder where your recipes are stored</li> <li>Select the recipes you want to export or use the checkbox at the top of the list to select all of them</li> <li>Click on the three dot Actions and press Download</li> </ol> <p>You will get a <code>Recipes.zip</code> file. Simply upload the file and choose the Nextcloud Cookbook type.</p> <p>Folder Structure</p> <p>Importing only works if the folder structure is correct. If you do not use the standard path or create the  zip file in any other way make sure the structure is as follows <pre><code>Recipes.zip/\n\u2514\u2500\u2500 Recipes/\n    \u251c\u2500\u2500 Recipe1/\n    \u2502   \u251c\u2500\u2500 recipe.json\n    \u2502   \u2514\u2500\u2500 full.jpg\n    \u2514\u2500\u2500 Recipe2/\n        \u251c\u2500\u2500 recipe.json\n        \u2514\u2500\u2500 full.jpg\n</code></pre></p>"},{"location":"features/import_export/#mealie","title":"Mealie","text":"<p>Mealie provides structured data similar to nextcloud. </p> <p>To migrate your recipes </p> <ol> <li>Go to your Mealie settings and create a new Backup.</li> <li>Download the backup by clicking on it and pressing download (this wasn't working for me, so I had to manually pull it from the server).</li> <li>Upload the entire <code>.zip</code> file to the importer page and import everything.</li> </ol>"},{"location":"features/import_export/#chowdown","title":"Chowdown","text":"<p>Chowdown stores all your recipes in plain text markdown files in a directory called <code>_recipes</code>.  Images are saved in a directory called <code>images</code>.</p> <p>In order to import your Chowdown recipes simply create a <code>.zip</code> file from those two folders and import them.  The folder structure should look as follows</p> <p>_recipes</p> <p>For some reason chowdown uses <code>_</code> before the <code>recipes</code> folder. To avoid confusion the import supports both <code>_recipes</code> and <code>recipes</code></p> <pre><code>Recipes.zip/\n    \u251c\u2500\u2500 _recipes/\n    \u2502   \u251c\u2500\u2500 recipe one.md\n    \u2502   \u251c\u2500\u2500 recipe two.md\n    \u2502   \u2514\u2500\u2500 ...\n    \u2514\u2500\u2500 images/\n        \u251c\u2500\u2500 image-name.jpg\n        \u251c\u2500\u2500 second-image-name.jpg\n        \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"features/import_export/#safron","title":"Safron","text":"<p>Go to your safron settings page and export your recipes. Then simply upload the entire <code>.zip</code> file to the importer.</p> <p>Images</p> <p>Safron exports do not contain any images. They will be lost during import.</p>"},{"location":"features/import_export/#paprika","title":"Paprika","text":"<p>A Paprika export contains a folder with a html representation of your recipes and a <code>.paprikarecipes</code> file.</p> <p>The <code>.paprikarecipes</code> file is basically just a zip with gzipped contents. Simply upload the whole file and import  all your recipes. </p>"},{"location":"features/import_export/#pepperplate","title":"Pepperplate","text":"<p>Pepperplate provides a <code>.zip</code> file containing all of your recipes as <code>.txt</code> files. These files are well-structured and allow the import of all data without losing anything.</p> <p>Simply export the recipes from Pepperplate and upload the zip to Tandoor. Images are not included in the export and  thus cannot be imported.</p>"},{"location":"features/import_export/#cheftap","title":"ChefTap","text":"<p>ChefTaps allows you to export your recipes from the app (I think). The export is a zip file containing a folder called <code>cheftap_export</code> which in turn contains <code>.txt</code> files with your recipes.</p> <p>This format is basically completely unstructured and every export looks different. This makes importing it very hard and leads to suboptimal results. Images are also not supported as they are not included in the export (at least  the tests I had).</p> <p>Usually the import should recognize all ingredients and put everything else into the instructions. If your import fails or is worse than this feel free to provide me with more example data and I can try to improve the importer.</p> <p>As ChefTap cannot import these files anyway there won't be an exporter implemented in Tandoor.</p>"},{"location":"features/import_export/#mealmaster","title":"MealMaster","text":"<p>Meal master can be imported by uploading one or more meal master files.  The files should either be <code>.txt</code>, <code>.MMF</code> or <code>.MM</code> files. </p> <p>The MealMaster spec allows for many variations. Currently, only the one column format for ingredients is supported. Second line notes to ingredients are currently also not imported as a note but simply put into the instructions. If you have MealMaster recipes that cannot be imported feel free to raise an issue.</p>"},{"location":"features/import_export/#rezkonv","title":"RezKonv","text":"<p>The RezKonv format is primarily used in the german recipe manager RezKonv Suite.  To migrate from RezKonv Suite to Tandoor select <code>Export &gt; Gesamtes Kochbuch exportieren</code> (the last option in the export menu). The generated file can simply be imported into Tandoor.</p> <p>As I only had limited sample data feel free to open an issue if your RezKonv export cannot be imported.</p>"},{"location":"features/import_export/#recipekeeper","title":"Recipekeeper","text":"<p>Recipe keeper allows you to export a zip file containing recipes and images using its apps.  This zip file can simply be imported into Tandoor.</p>"},{"location":"features/import_export/#openeats","title":"OpenEats","text":"<p>OpenEats does not provide any way to export the data using the interface. Luckily it is relatively easy to export it from the command line. You need to run the command <code>python manage.py dumpdata recipe ingredient</code> inside of the application api container. If you followed the default installation method you can use the following command <code>docker-compose -f docker-prod.yml run --rm --entrypoint 'sh' api ./manage.py dumpdata recipe ingredient</code>. This command might also work <code>docker exec -it openeats_api_1 ./manage.py dumpdata recipe ingredient rating recipe_groups &gt; recipe_ingredients.json</code></p> <p>Store the outputted json string in a <code>.json</code> file and simply import it using the importer. The file should look something like this <pre><code>[\n{\n\"model\":\"recipe.recipe\",\n\"pk\":1,\n\"fields\":{\n\"title\":\"Tasty Chili\",\n...\n}\n},\n...\n{\n\"model\":\"ingredient.ingredientgroup\",\n\"pk\":1,\n\"fields\":{\n\"title\":\"Veges\",\n\"recipe\":1\n}\n},\n...\n{\n\"model\":\"ingredient.ingredient\",\n\"pk\":1,\n\"fields\":{\n\"title\":\"black pepper\",\n\"numerator\":1.0,\n\"denominator\":1.0,\n\"measurement\":\"dash\",\n\"ingredient_group\":1\n}\n}\n]\n</code></pre></p> <p>To import your images you'll need to create the folder <code>openeats-import</code> in your Tandoor's <code>recipes</code> media folder (which is usually found inside <code>/opt/recipes/mediafiles</code>). After that you'll need to copy the <code>/code/site-media/upload</code> folder from the openeats API docker container to the <code>openeats</code> folder you created. You should now have the file path <code>/opt/recipes/mediafiles/recipes/openeats-import/upload/...</code> in Tandoor.</p>"},{"location":"features/import_export/#plantoeat","title":"Plantoeat","text":"<p>Plan to eat allows you to export a text file containing all your recipes. Simply upload that text file to Tandoor to import all recipes</p>"},{"location":"features/import_export/#cookbookapp","title":"CookBookApp","text":"<p>CookBookApp can export .zip files containing .html files. Upload the entire ZIP to Tandoor to import all included recipes.</p>"},{"location":"features/import_export/#copymethat","title":"CopyMeThat","text":"<p>CopyMeThat can export .zip files containing an <code>.html</code> file as well as a folder containing all the images. Upload the entire ZIP to Tandoor to import all included recipes.</p>"},{"location":"features/import_export/#cookmate","title":"Cookmate","text":"<p>Cookmate allows you to export a <code>.mcb</code> file which you can simply upload to tandoor and import all your recipes.</p>"},{"location":"features/import_export/#recettetek","title":"RecetteTek","text":"<p>RecetteTek exports are <code>.rtk</code> files which can simply be uploaded to tandoor to import all your recipes. </p>"},{"location":"features/import_export/#rezeptsuitede","title":"Rezeptsuite.de","text":"<p>Rezeptsuite.de exports are <code>.xml</code> files which can simply be uploaded to tandoor to import all your recipes.</p> <p>It appears that Reptsuite, depending on the client, might export a <code>.zip</code> file containing a <code>.cml</code> file. If this happens just unzip the zip file and change <code>.cml</code> to <code>.xml</code> to import your recipes. </p>"},{"location":"features/import_export/#melarecipes","title":"Melarecipes","text":"<p>Melarecipes provides multiple export formats but only the <code>MelaRecipes</code> format can export the complete collection. Perform this export and open the <code>.melarecipes</code> file using your favorite archive opening program (e.g 7zip).  Repeat this if the file contains another <code>.melarecipes</code> file until you get a list of one or many <code>.melarecipe</code> files. Upload all <code>.melarecipe</code> files you want to import to tandoor and start the import.</p>"},{"location":"features/import_export/#pdf","title":"PDF","text":"<p>The PDF Exporter is an experimental feature that uses the puppeteer browser renderer to render each recipe and export it to PDF.  For that to work it downloads a chromium binary of about 140 MB to your server and then renders the PDF files using that. </p> <p>Since that is something some server administrators might not want there the PDF exporter is disabled by default and can be enabled with <code>ENABLE_PDF_EXPORT=1</code> in <code>.env</code>.</p> <p>See this issue for more discussion on this and  this issue for the future plans to support server side rendering.</p>"},{"location":"features/shopping/","title":"Shopping","text":"<p>WIP</p> <p>While being around for a while there are still a lot of features that i plan on adding to the shopping list. You can see an overview of what is still planned on this issue.</p> <p>Shopping lists allow you to easily convert a recipe or even a whole meal plan into a shopping list. From there you can either use it on the site or export it to your shopping list of choice.  It also includes automatic supermarket specific ordering.</p> <p></p>"},{"location":"features/shopping/#create-shopping-lists","title":"Create Shopping Lists","text":"<p>You have three options to create a shopping list</p> <ol> <li>Open a recipe of your choice. From the context menu choose <code>Add to Shoppinglist</code> and create a new list with the recipe already added.</li> <li>After adding recipes to the meal plan you can click the little shopping cart icon to add the recipes to the shopping list.    They will be shown below the plan, from there you can open a new shopping list with them.</li> <li>The last option is to open the shopping list page and click the little plus icon to create a new list.</li> </ol>"},{"location":"features/shopping/#supermarket-ordering","title":"Supermarket Ordering","text":"<p>WIP</p> <p>This feature is relatively new and I did not have the time to completely polished it yet, that said  it already works quite well.</p> <p>You can create Supermarket Categories and Supermarkets in the admin interface. After setting this up you can choose a supermarket for each shopping list. This will automatically show the categories configured for this supermarket in the order specified. All Foods that are not yet categorized can be dragged into their category, this will save the categories for the future.</p>"},{"location":"features/shopping/#sharing-autosync","title":"Sharing &amp; Autosync","text":"<p>If you want to collaborate on the creation and usage of the shopping list you can add a user to the list of shared users. Each user now has access to the list and can edit it. </p> <p>When checking items in viewing mode the change is synced to all other clients that currently have the same list open. You can set the syncing interval in your user settings.</p>"},{"location":"features/shopping/#other-features","title":"Other Features","text":"<p>There are a few more features worth pointing out</p> <ol> <li>You can export recipes for use in other applications (Google Keep, etc.) by using the export button</li> <li>In the export popup you can define a prefix to be put before each row in case an external app requires that</li> <li>Marking a shopping list as finished will hide it from the shopping list page</li> </ol>"},{"location":"features/telegram_bot/","title":"Telegram bot","text":"<p>The telegram bot is meant to simplify certain interactions with Tandoor. It is currently very basic but might be expanded in the future.</p> <p>Experimental</p> <p>This feature is considered experimental. You can use it and it should not break anything but you might be  required to update your configuration in the future. The setup is also definitely not user-friendly, this will likely improve if the feature is well-received/expanded.</p> <p>Public IP/Domain</p> <p>To use the Telegram Bot you will need an installation that is accessible from the outside, otherwise telegram can't send messages. This could be circumvented using the polling API but this is currently not implemented.</p>"},{"location":"features/telegram_bot/#shopping-bot","title":"Shopping Bot","text":"<p>The shopping bot will add any message you send it to your latest open shopping list.</p> <p>To get a shopping bot follow these steps</p> <ol> <li>Create a new Telegram Bot using the BotFather</li> <li>If you want to use the bot with multiple persons add the bot to a group and grant it admin privileges</li> <li>Open the Admin Page (click your username, then admin) and select <code>Telegram Bots</code></li> <li>Create a new Bot</li> <li>token: the token obtained in step one </li> <li>space: your space (usually Default)</li> <li>user: to the user the bot is meant for (determines the shopping list used)</li> <li>chat id: if you know where messages will be sent from enter the chat ID, otherwise it is set to the first chat the bot received a message from</li> <li>Visit your installation at <code>recipes.mydomin.tld/telegram/setup/&lt;botid&gt;</code> with botid being the ID of the bot you just created    You should see the following message:     <pre><code>{\n    \"hook_url\": \"https://recipes.mydomin.tld/telegram/hook/c0c08de9-5e1e-4480-8312-3e256af61340/\",\n    \"create_response\": {\n        \"ok\": true,\n        \"result\": true,\n        \"description\": \"Webhook was set\"\n    },\n    \"info_response\": {\n        \"ok\": true,\n        \"result\": {\n            \"url\": \"recipes.mydomin.tld/telegram/hook/&lt;webhook_token&gt;\",\n            \"has_custom_certificate\": false,\n            \"pending_update_count\": 0,\n            \"max_connections\": 40,\n            \"ip_address\": \"46.4.105.116\"\n        }\n    }\n}\n</code></pre></li> </ol> <p>You should now be able to send messages to the bot and have the entries appear in your latest shopping list.</p>"},{"location":"features/telegram_bot/#resetting","title":"Resetting","text":"<p>To reset a bot open <code>recipes.mydomin.tld/telegram/remove/&lt;botid&gt;</code></p>"},{"location":"features/templating/","title":"Templating","text":"<p>Danger</p> <p>The version containing Templating is not yet released! This documentation is only to illustrate the pending changes facilitate the discussion.</p> <p>With the Version <code>0.14.0</code> support for using a custom Jinja2 Template in recipe step instructions has been added.</p> <p>This allows you to write ingredients with their corresponding amount directly inside the text while still profiting from recipe scaling.</p> <p></p> <p>Info</p> <p>Templating is a very new feature and still WIP. Feel free to open an issue to provide feedback and ideas. Please also refer to Issue #218 where this feature has been discussed.</p>"},{"location":"features/templating/#using-templating","title":"Using Templating","text":"<p>Currently the only available variable in the Templating context is <code>ingredients</code>.</p> <p><code>ingredients</code> is an array that contains all ingredients of the current recipe step. You can access an ingredient by using <code>{{ ingredients[&lt;index in list&gt;] }}</code> where the index refers to the position in the list of ingredients starting with zero. You can also use the interaction menu of the ingredient to copy its reference.</p> <p>Warning</p> <p>Please note that changing the order of the ingredients will break the reference (or at least make it useless). See the technical reasoning for more information on why it is this way.</p> <p></p> <p>You can also access only the amount, unit, note or food inside your instruction text using <pre><code>{{ ingredients[0].amount }}\n{{ ingredients[0].unit }}\n{{ ingredients[0].food }}\n{{ ingredients[0].note }}\n</code></pre></p>"},{"location":"features/templating/#technical-reasoning","title":"Technical Reasoning","text":"<p>There are several options how the ingredients in the list can be related to the Template Context in the Text.</p> <p>The template could access them by ID, the food name or the position in the list. All options have their benefits and disadvantages.</p> <ol> <li>ID: ugly to write and read when not rendered and also more complex from a technical standpoint</li> <li>Name: very nice to read and easy but does not work when a food occurs twice in a step. Could have workaround but would then be inconsistent.</li> <li>Position: easy to write and understand but breaks when ordering is changed and not really nice to read when instructions are not rendered.</li> </ol> <p>I decided to go for the position based system. If you know of any better way feel free to open an issue or PR.</p>"},{"location":"install/docker/","title":"Docker","text":"<p>Recommended Installation</p> <p>Setting up this application using Docker is recommended. This does not mean that other options are bad, just that support is much easier for this setup.</p> <p>It is possible to install this application using many different Docker configurations.</p> <p>Please read the instructions on each example carefully and decide if this is the way for you.</p>"},{"location":"install/docker/#docker","title":"Docker","text":"<p>The docker image (<code>vabene1111/recipes</code>) simply exposes the application on the container's port <code>8080</code>.</p> <p>It can be run and accessed on port 80 using:</p> <pre><code>docker run -d \\\n-v \"$(pwd)\"/staticfiles:/opt/recipes/staticfiles \\\n-v \"$(pwd)\"/mediafiles:/opt/recipes/mediafiles \\\n-p 80:8080 \\\n-e SECRET_KEY=YOUR_SECRET_KEY \\\n-e DB_ENGINE=django.db.backends.postgresql \\\n-e POSTGRES_HOST=db_recipes \\\n-e POSTGRES_PORT=5432 \\\n-e POSTGRES_USER=djangodb \\\n-e POSTGRES_PASSWORD=YOUR_POSTGRES_SECRET_KEY \\\n-e POSTGRES_DB=djangodb \\\n--name recipes_1 \\\nvabene1111/recipes\n</code></pre> <p>Please make sure, if you run your image this way, to consult the .env.template file in the GitHub repository to verify if additional environment variables are required for your setup.</p> <p>Also, don't forget to replace the placeholders for <code>SECRET_KEY</code> and <code>POSTGRES_PASSWORD</code>!</p>"},{"location":"install/docker/#versions","title":"Versions","text":"<p>There are different versions (tags) released on Docker Hub.</p> <ul> <li>latest Default image. The one you should use if you don't know that you need anything else.</li> <li>beta Partially stable version that gets updated every now and then. Expect to have some problems.</li> <li>develop If you want the most bleeding edge version with potentially many breaking changes feel free to use this version (not recommended!).</li> <li>X.Y.Z each released version has its own image. If you need to revert to an old version or want to make sure you stay on one specific use these tags.</li> </ul> <p>No Downgrading</p> <p>There is currently no way to migrate back to an older version as there is no mechanism to downgrade the database. You could probably do it but I cannot help you with that. Choose wisely if you want to use the unstable images. That said beta should usually be working if you like frequent updates and new stuff.</p>"},{"location":"install/docker/#docker-compose","title":"Docker Compose","text":"<p>The main, and also recommended, installation option for this application is Docker Compose.</p> <ol> <li>Choose your <code>docker-compose.yml</code> from the examples below.</li> <li>Download the <code>.env</code> configuration file with <code>wget</code> <pre><code>wget https://raw.githubusercontent.com/vabene1111/recipes/develop/.env.template -O .env\n</code></pre></li> <li>Edit it accordingly (you NEED to set <code>SECRET_KEY</code> and <code>POSTGRES_PASSWORD</code>).</li> <li>Start your container using <code>docker-compose up -d</code>.</li> </ol>"},{"location":"install/docker/#plain","title":"Plain","text":"<p>This configuration exposes the application through a containerized nginx web server on port 80 of your machine. Be aware that having some other web server or container running on your host machine on port 80 will block this from working.</p> <pre><code>wget https://raw.githubusercontent.com/vabene1111/recipes/develop/docs/install/docker/plain/docker-compose.yml\n</code></pre> <pre><code>version: \"3\"\nservices:\ndb_recipes:\nrestart: always\nimage: postgres:15-alpine\nvolumes:\n- ./postgresql:/var/lib/postgresql/data\nenv_file:\n- ./.env\n\nweb_recipes:\nrestart: always\nimage: vabene1111/recipes\nenv_file:\n- ./.env\nvolumes:\n- staticfiles:/opt/recipes/staticfiles\n# Do not make this a bind mount, see https://docs.tandoor.dev/install/docker/#volumes-vs-bind-mounts\n- nginx_config:/opt/recipes/nginx/conf.d\n- ./mediafiles:/opt/recipes/mediafiles\ndepends_on:\n- db_recipes\n\nnginx_recipes:\nimage: nginx:mainline-alpine\nrestart: always\nports:\n- 80:80\nenv_file:\n- ./.env\ndepends_on:\n- web_recipes\nvolumes:\n# Do not make this a bind mount, see https://docs.tandoor.dev/install/docker/#volumes-vs-bind-mounts\n- nginx_config:/etc/nginx/conf.d:ro\n- staticfiles:/static:ro\n- ./mediafiles:/media:ro\n\nvolumes:\nnginx_config:\nstaticfiles:\n</code></pre> <p>Note</p> <p>Don't forget to download and configure your <code>.env</code> file!</p>"},{"location":"install/docker/#reverse-proxy","title":"Reverse Proxy","text":"<p>Most deployments will likely use a reverse proxy.</p> <p>If your reverse proxy is not listed below, please refer to chapter Others.</p>"},{"location":"install/docker/#traefik","title":"Traefik","text":"<p>If you use Traefik, this configuration is the one for you.</p> <p>Info</p> <p>Traefik can be a little confusing to setup. Please refer to their excellent documentation. If that does not help, this little example might be for you.</p> <pre><code>wget https://raw.githubusercontent.com/vabene1111/recipes/develop/docs/install/docker/traefik-nginx/docker-compose.yml\n</code></pre> <pre><code>version: \"3\"\nservices:\ndb_recipes:\nrestart: always\nimage: postgres:15-alpine\nvolumes:\n- ./postgresql:/var/lib/postgresql/data\nenv_file:\n- ./.env\nnetworks:\n- default\n\nweb_recipes:\nrestart: always\nimage: vabene1111/recipes\nenv_file:\n- ./.env\nvolumes:\n- staticfiles:/opt/recipes/staticfiles\n# Do not make this a bind mount, see https://docs.tandoor.dev/install/docker/#volumes-vs-bind-mounts\n- nginx_config:/opt/recipes/nginx/conf.d\n- ./mediafiles:/opt/recipes/mediafiles\ndepends_on:\n- db_recipes\nnetworks:\n- default\n\nnginx_recipes:\nimage: nginx:mainline-alpine\nrestart: always\nenv_file:\n- ./.env\nvolumes:\n# Do not make this a bind mount, see https://docs.tandoor.dev/install/docker/#volumes-vs-bind-mounts\n- nginx_config:/etc/nginx/conf.d:ro\n- staticfiles:/static:ro\n- ./mediafiles:/media:ro\nlabels: # traefik example labels\n- \"traefik.enable=true\"\n- \"traefik.http.routers.recipes.rule=Host(`recipes.mydomain.com`, `recipes.myotherdomain.com`)\"\n- \"traefik.http.routers.recipes.entrypoints=web_secure\" # your https endpoint\n- \"traefik.http.routers.recipes.tls.certresolver=le_resolver\" # your cert resolver\ndepends_on:\n- web_recipes\nnetworks:\n- default\n- traefik\n\nnetworks:\ndefault:\ntraefik: # This is your external traefik network\nexternal: true\n\nvolumes:\nnginx_config:\nstaticfiles:\n</code></pre> <p>Note</p> <p>Don't forget to download and configure your <code>.env</code> file!</p>"},{"location":"install/docker/#jwilders-nginx-proxy","title":"jwilder's Nginx-proxy","text":"<p>This is a docker compose example using jwilder's nginx reverse proxy in combination with jrcs's letsencrypt companion.</p> <p>Please refer to the appropriate documentation on how to setup the reverse proxy and networks.</p> <p>Adjust client_max_body_size</p> <p>By using jwilder's Nginx-proxy, uploads will be restricted to 1 MB file size. This can be resolved by adjusting the <code>client_max_body_size</code> variable in the jwilder nginx configuration. </p> <p>Remember to add the appropriate environment variables to the <code>.env</code> file:</p> <pre><code>VIRTUAL_HOST=\nLETSENCRYPT_HOST=\nLETSENCRYPT_EMAIL=\n</code></pre> <pre><code>wget https://raw.githubusercontent.com/vabene1111/recipes/develop/docs/install/docker/nginx-proxy/docker-compose.yml\n</code></pre> <pre><code>version: \"3\"\nservices:\ndb_recipes:\nrestart: always\nimage: postgres:15-alpine\nvolumes:\n- ./postgresql:/var/lib/postgresql/data\nenv_file:\n- ./.env\nnetworks:\n- default\n\nweb_recipes:\nrestart: always\nimage: vabene1111/recipes\nenv_file:\n- ./.env\nvolumes:\n- staticfiles:/opt/recipes/staticfiles\n# Do not make this a bind mount, see https://docs.tandoor.dev/install/docker/#volumes-vs-bind-mounts\n- nginx_config:/opt/recipes/nginx/conf.d\n- ./mediafiles:/opt/recipes/mediafiles\ndepends_on:\n- db_recipes\nnetworks:\n- default\n\nnginx_recipes:\nimage: nginx:mainline-alpine\nrestart: always\nenv_file:\n- ./.env\ndepends_on:\n- web_recipes\nvolumes:\n# Do not make this a bind mount, see https://docs.tandoor.dev/install/docker/#volumes-vs-bind-mounts\n- nginx_config:/etc/nginx/conf.d:ro\n- staticfiles:/static:ro\n- ./mediafiles:/media:ro\nnetworks:\n- default\n- nginx-proxy\n\nnetworks:\ndefault:\nnginx-proxy:\nexternal:\nname: nginx-proxy\n\nvolumes:\nnginx_config:\nstaticfiles:\n</code></pre> <p>Note</p> <p>Don't forget to download and configure your <code>.env</code> file!</p>"},{"location":"install/docker/#nginx-swag-by-linuxserver","title":"Nginx Swag by LinuxServer","text":"<p>This container is an all in one solution created by LinuxServer.io.</p> <p>It contains templates for popular apps, including Tandoor Recipes, so you don't have to manually configure nginx and discard the template provided in Tandoor repo. Tandoor config is called <code>recipes.subdomain.conf.sample</code> which you can adapt for your instance.</p> <p>If you're running Swag on the default port, you'll just need to change the container name to yours.</p> <p>If your running Swag on a custom port, some headers must be changed:</p> <ul> <li>Create a copy of <code>proxy.conf</code></li> <li>Replace <code>proxy_set_header X-Forwarded-Host $host;</code> and <code>proxy_set_header Host $host;</code> to<ul> <li><code>proxy_set_header X-Forwarded-Host $http_host;</code> and <code>proxy_set_header Host $http_host;</code></li> </ul> </li> <li>Update <code>recipes.subdomain.conf</code> to use the new file</li> <li>Restart the linuxserver/swag container and Recipes will work correctly</li> </ul> <p>More information here.</p> <p>In both cases, also make sure to mount <code>/media/</code> in your swag container to point to your Tandoor Recipes Media directory.</p> <p>Please refer to the appropriate documentation for the container setup.</p> <p>For step-by-step instructions to set this up from scratch, see this example.</p>"},{"location":"install/docker/#pure-nginx","title":"Pure Nginx","text":"<p>If you have Nginx installed locally on your host system without using any third party integration like Swag or similar, this is for you.</p> <p>You can use the Docker-Compose file from Plain.</p> <p>Adjust Docker-Compose file</p> <p>Replace <code>80:80</code> with <code>PORT:80</code> with PORT being your desired outward-facing port. In the nginx config example below, 8080 is used.</p> <p>An example configuration with LetsEncrypt to get you started can be seen below. Please note, that since every setup is different, you might need to adjust some things.</p> <p>Placeholders</p> <p>Don't forget to replace the domain and port.</p> <pre><code>server {\nif ($host = recipes.mydomain.tld) { # replace domain\nreturn 301 https://$host$request_uri;\n}\n\nserver_name recipes.mydomain.tld; # replace domain\nlisten 80;\nreturn 404;\n}\nserver {\nserver_name recipes.mydomain.tld; # replace domain\nlisten 443 ssl;\n\nssl_certificate /etc/letsencrypt/live/recipes.mydomain.tld/fullchain.pem; # replace domain\nssl_certificate_key /etc/letsencrypt/live/recipes.mydomain.tld/privkey.pem; # replace domain\ninclude /etc/letsencrypt/options-ssl-nginx.conf;\nssl_dhparam /etc/letsencrypt/ssl-dhparams.pem;\n\nlocation / {\nproxy_set_header Host $http_host; # try $host instead if this doesn't work\nproxy_set_header X-Forwarded-Proto $scheme;\nproxy_pass http://127.0.0.1:8080; # replace port\nproxy_redirect http://127.0.0.1:8080 https://recipes.domain.tld; # replace port and domain\n}\n}\n</code></pre> <p>Note</p> <p>Don't forget to download and configure your <code>.env</code> file!</p>"},{"location":"install/docker/#apache","title":"Apache","text":"<p>You can use the Docker-Compose file from Plain.</p> <p>Adjust Docker-Compose file</p> <p>Replace <code>80:80</code> with <code>PORT:80</code> with PORT being your desired outward-facing port. In the Apache config example below, 8080 is used.</p> <p>If you use e.g. LetsEncrypt for SSL encryption, you can use the example configuration from solaris7590 below.</p> <p>Placeholders</p> <p>Don't forget to replace the domain and port.</p> <pre><code>&lt;IfModule mod_ssl.c&gt;\n&lt;VirtualHost *:80&gt;\nServerAdmin webmaster@mydomain.de # replace domain\n        ServerName mydomain.de # replace domain\n\n        Redirect permanent / https://mydomain.de/ # replace domain\n    &lt;/VirtualHost&gt;\n\n&lt;VirtualHost *:443&gt;\nServerAdmin webmaster@mydomain.de # replace domain\n        ServerName mydomain.de # replace domain\n\n        SSLEngine on\n\nRequestHeader set X-Forwarded-Proto \"https\"\nHeader always set Access-Control-Allow-Origin \"*\"\n\nProxyPreserveHost  On\nProxyRequests Off\nProxyPass / http://localhost:8080/ # replace port\n        ProxyPassReverse / http://localhost:8080/ # replace port\n\n        SSLCertificateFile /etc/letsencrypt/live/mydomain.de/fullchain.pem # replace domain/path\n        SSLCertificateKeyFile /etc/letsencrypt/live/mydomain.de/privkey.pem # replace domain/path\n        Include /etc/letsencrypt/options-ssl-apache.conf\n\nErrorLog ${APACHE_LOG_DIR}/recipes_error.log\n        CustomLog ${APACHE_LOG_DIR}/recipes_access.log combined\n    &lt;/VirtualHost&gt;\n&lt;/IfModule&gt;\n</code></pre> <p>If you're having issues with the example configuration above, you can try beedaddy's example config.</p> <p>Note</p> <p>Don't forget to download and configure your <code>.env</code> file!</p>"},{"location":"install/docker/#others","title":"Others","text":"<p>If you use none of the above mentioned reverse proxies or want to use an existing one on your host machine (like a local nginx or Caddy), simply use the Plain setup above and change the outbound port to one of your liking.</p> <p>An example port config (inside the respective docker-compose.yml) would be: <code>8123:80</code> instead of the <code>80:80</code> or if you want to be sure, that Tandoor is just accessible via your proxy and don't wanna bother with your firewall, then <code>127.0.0.1:8123:80</code> is a viable option too.</p> <p>Note</p> <p>Don't forget to download and configure your <code>.env</code> file!</p>"},{"location":"install/docker/#additional-information","title":"Additional Information","text":""},{"location":"install/docker/#nginx-vs-gunicorn","title":"Nginx vs Gunicorn","text":"<p>All examples use an additional <code>nginx</code> container to serve mediafiles and act as the forward facing webserver. This is technically not required but very much recommended.</p> <p>I do not 100% understand the deep technical details but the developers of gunicorn, the WSGi server that handles the Python execution, explicitly state that it is not recommended to deploy without nginx. You will also likely not see any decrease in performance or a lot of space used as nginx is a very light container.</p> <p>Info</p> <p>Even if you run behind a reverse proxy as described above, using an additional nginx container is the recommended option.</p> <p>If you run a small private deployment and don't care about performance, security and whatever else feel free to run without a nginx container.</p> <p>Warning</p> <p>When running without nginx make sure to enable <code>GUNICORN_MEDIA</code> in the <code>.env</code>. Without it, media files will be uploaded but not shown on the page.</p> <p>For additional information please refer to the 0.9.0 Release and Issue 201 where these topics have been discussed. See also refer to the official gunicorn docs.</p>"},{"location":"install/docker/#nginx-config","title":"Nginx Config","text":"<p>In order to give the user (you) the greatest amount of freedom when choosing how to deploy this application the webserver is not directly bundled with the Docker image.</p> <p>This has the downside that it is difficult to supply the configuration to the webserver (e.g. nginx). Up until version <code>0.13.0</code>, this had to be done manually by downloading the nginx config file and placing it in a directory that was then mounted into the nginx container.</p> <p>From version <code>0.13.0</code>, the config file is supplied using the application image (<code>vabene1111/recipes</code>). It is then mounted to the host system and from there into the nginx container.</p> <p>This is not really a clean solution, but I could not find any better alternative that provided the same amount of usability. If you know of any better way, feel free to open an issue.</p>"},{"location":"install/docker/#volumes-vs-bind-mounts","title":"Volumes vs Bind Mounts","text":"<p>Since I personally prefer to have my data where my <code>docker-compose.yml</code> resides, bind mounts are used in the example configuration files for all user generated data (e.g. Postgresql and media files).</p> <p>Warning</p> <p>Please note that there is a difference in functionality between the two and you cannot always simply interchange them.</p> <p>You can move everything to volumes if you prefer it this way, but you cannot convert the nginx config file to a bind mount. If you do so you will have to manually create the nginx config file and restart the container once after creating it.</p>"},{"location":"install/docker/#required-headers","title":"Required Headers","text":"<p>Please be sure to supply all required headers in your nginx/Apache/Caddy/... configuration!</p> <p>nginx: <pre><code>location / {\nproxy_set_header Host $http_host; # try $host instead if this doesn't work\nproxy_set_header X-Forwarded-Proto $scheme;\nproxy_pass http://127.0.0.1:8080; # replace port\nproxy_redirect http://127.0.0.1:8080 https://recipes.domain.tld; # replace port and domain\n}\n</code></pre></p> <p>Apache: <pre><code>RequestHeader set X-Forwarded-Proto \"https\"\nHeader always set Access-Control-Allow-Origin \"*\"\n\nProxyPreserveHost  On\nProxyRequests Off\nProxyPass / http://localhost:8080/ # replace port\nProxyPassReverse / http://localhost:8080/ # replace port\n</code></pre></p>"},{"location":"install/docker/#setup-issues-on-raspberry-pi","title":"Setup issues on Raspberry Pi","text":"<p>Info</p> <p>Always wait at least 2-3 minutes after the very first start, since migrations will take some time!</p> <p>Warning</p> <p>If you want to use Tandoor on a Raspberry Pi running a 32-bit operating system you will need to use the following docker image tags: <code>latest-raspi</code>, <code>beta-raspi</code> and the versioned <code>&lt;x.y.z&gt;-raspi</code> We strongly recommend using the new 64-bit Raspian image as the 32-bit version is not tested.</p> <p>If you're having issues with installing Tandoor on your Raspberry Pi or similar device, follow these instructions:</p> <ul> <li>Stop all Tandoor containers (<code>docker-compose down</code>)</li> <li>Delete local database folder (usually 'postgresql' in the same folder as your 'docker-compose.yml' file)</li> <li>Start Tandoor containers again (<code>docker-compose up -d</code>)</li> <li>Wait for at least 2-3 minutes and then check if everything is working now (migrations can take quite some time!)</li> <li>If not, check logs of the web_recipes container with <code>docker logs &lt;container_name&gt;</code> and make sure that all migrations are indeed already done</li> </ul>"},{"location":"install/docker/#sub-path-nginx-config","title":"Sub Path nginx config","text":"<p>If hosting under a sub-path you might want to change the default nginx config (which gets mounted through the named volume from the application container into the nginx container) with the following config. </p> <pre><code>location /my_app { # change to subfolder name\ninclude /config/nginx/proxy.conf; proxy_pass https://mywebapp.com/; # change to your host name:port\nproxy_set_header Host $host;\nproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\nproxy_set_header X-Script-Name /my_app; # change to subfolder name\nproxy_cookie_path / /my_app; # change to subfolder name\n}\n\nlocation /media/ {\ninclude /config/nginx/proxy.conf;\nalias /mediafiles/;\nclient_max_body_size 16M;\n\n}\n\nlocation /static/ {\ninclude /config/nginx/proxy.conf;\nalias /staticfiles/;\nclient_max_body_size 16M;\n\n}\n</code></pre>"},{"location":"install/homeassistant/","title":"Homeassistant","text":"<p>Community Contributed</p> <p>This guide was contributed by the community and is neither officially supported, nor updated or tested.  Many thanks to alexbelgium for making implementing everything required to have  Tandoor run in HA.</p> <p> </p>"},{"location":"install/homeassistant/#introduction","title":"Introduction","text":"<p>Home Assistant (HA) is a free and open-source software for home automation designed to be a central control system for smart home devices with a focus on local control and privacy. It can be accessed through a web-based user interface by using companion apps for Android and iOS, or by voice commands via a supported virtual assistant such as Google Assistant or Amazon Alexa.</p> <p>It can be installed as a standalone Operating System on a dedicated system, making it easy to deploy and maintain through Over The Air updates. It can also be installed as Docker container.</p> <p>In addition to its large depth of native functions, modular addons can be added to expand its functions. An addon for Tandoor Recipes was created, allowing to store the server on the Home Assistant devices and access the user interface either through direct web access or securely through the native Home Assistant app.</p>"},{"location":"install/homeassistant/#installation","title":"Installation","text":"<ol> <li>Once you have a running Home Assistant system, the next step is to add the alexbelgium's custom repository to your system. This is performed by clicking on the button below, and simply filling your HA url. </li> <li>Install the addon </li> <li>Set the add-on options to your preferences (see below)</li> <li>Start the add-on</li> <li>Check the logs of the add-on to see if everything went well.</li> <li>Open the webUI (either through Ingress, or direct webUI with http://homeassistant.local:9928) and adapt the software options</li> </ol>"},{"location":"install/homeassistant/#configuration","title":"Configuration","text":"<p>The following environment variable are configurable from the addon options. Please see the Docker documentation for more information on how they should be filled.</p> <pre><code>Required :\n\"ALLOWED_HOSTS\": \"your system url\", # You need to input your homeassistant urls (comma separated, without space) to allow ingress to work\n\"DB_TYPE\": \"list(sqlite|postgresql_external|mariadb_addon)\" # Type of database to use. Mariadb_addon allows to be automatically configured if the maria_db addon is already installed on your system. Sqlite is an internal database. For postgresql_external, you'll need to fill the below settings\n\"SECRET_KEY\": \"str\", # Your secret key\n\"PORT\": 9928 # By default, the webui is available on http://homeassistant.local:9928. If you ever need to change the port, you should never do it within the app, but only through this option\nOptional :\n\"POSTGRES_HOST\": \"str?\", # Needed for postgresql_external\n\"POSTGRES_PORT\": \"str?\", # Needed for postgresql_external\n\"POSTGRES_USER\": \"str?\", # Needed for postgresql_external\n\"POSTGRES_PASSWORD\": \"str?\", # Needed for postgresql_external\n\"POSTGRES_DB\": \"str?\" # Needed for postgresql_external\n</code></pre>"},{"location":"install/homeassistant/#updates-and-backups","title":"Updates and backups","text":"<p>The alexbelgium's repo incorporates a script that aligns every 3 days the addon to the containers released. Just wait a few hours for HA to refreshes its repo list and the uodate will be proposed automatically in your HA system.</p> <p>It is recommended to frequently backup. All data is stored outside of the addon, the main location <code>/config/addons_config/tandoor_recipes</code>, so be sure to backup this folder in addition to the addon itself when updating. If you have selected mariadb as database option, don't forget to also backup it.</p>"},{"location":"install/homeassistant/#support","title":"Support","text":"<p>Issues related to the addon itself should be reported on the maintainer repo.</p> <p>Issues related to HA should be reported on the HA Community Forum.</p> <p>Issues related to Tandoor recipes should be reported on this github repo.</p>"},{"location":"install/kubernetes/","title":"Kubernetes","text":"<p>Community Contributed</p> <p>This guide was contributed by the community and is neither officially supported, nor updated or tested.</p>"},{"location":"install/kubernetes/#k8s-setup","title":"K8s Setup","text":"<p>This is a setup which should be sufficient for production use. Be sure to replace the default secrets!</p>"},{"location":"install/kubernetes/#files","title":"Files","text":""},{"location":"install/kubernetes/#10-configmapyaml","title":"10-configmap.yaml","text":"<p>The nginx config map. This is loaded as nginx.conf in the nginx sidecar to configure nginx to deliver static content.</p>"},{"location":"install/kubernetes/#15-secretsyaml","title":"15-secrets.yaml","text":"<p>Contains secrets</p> <p>Replace them!</p> <p>This file is only here for a quick start. Be aware that changing secrets after installation will be messy and is not documented here. You should set new secrets before the installation. As you are reading this document before the installation ;-)</p> <p>Create your own postgresql passwords and the secret key for the django app.</p> <p>See also Managing Secrets using kubectl</p> <p>Replace <code>db-password</code>, <code>postgres-user-password</code> and <code>secret-key</code> with something - well - secret :-)</p> <pre><code>echo -n 'db-password' &gt; ./db-password.txt\necho -n 'postgres-user-password' &gt; ./postgres-password.txt\necho -n 'secret-key' | sha256sum | awk '{ printf $1 }' &gt; ./secret-key.txt\n</code></pre> <p>Delete the default secrets file <code>15-secrets.yaml</code> and generate the K8s secret from your files.</p> <pre><code>kubectl create secret generic recipes \\\n  --from-file=postgresql-password=./db-password.txt \\\n  --from-file=postgresql-postgres-password=./postgres-password.txt \\\n  --from-file=secret-key=./secret-key.txt\n</code></pre>"},{"location":"install/kubernetes/#20-service-accountyml","title":"20-service-account.yml","text":"<p>Creating service account <code>recipes</code> for deployment and stateful set.</p>"},{"location":"install/kubernetes/#30-pvcyaml","title":"30-pvc.yaml","text":"<p>The creation of the persistent volume claims for media and static content. May you want to increase the size. This expects to have a storage class installed.</p>"},{"location":"install/kubernetes/#40-sts-postgresqlyaml","title":"40-sts-postgresql.yaml","text":"<p>The PostgreSQL stateful set, based on a bitnami image. It runs a init container as root to do the preparations. The postgres container itself runs as a lower privileged user. The recipes app uses the database super user (postgres) as the recipes app is doing some db migrations on startup, which needs super user privileges.</p>"},{"location":"install/kubernetes/#45-service-dbyaml","title":"45-service-db.yaml","text":"<p>Creating the database service.</p>"},{"location":"install/kubernetes/#50-deploymentyaml","title":"50-deployment.yaml","text":"<p>The deployment first fires up a init container to do the database migrations and file modifications. This init container runs as root. The init container runs part of the boot.sh script from the <code>vabene1111/recipes</code> image. </p> <p>The deployment then runs two containers, the recipes-nginx and the recipes container which runs the gunicorn app. The nginx container gets it's nginx.conf via config map to deliver static content <code>/static</code> and <code>/media</code>. The guincorn container gets it's secret key and the database password from the secret <code>recipes</code>. <code>gunicorn</code> runs as user <code>nobody</code>.</p> <p>Currently, this deployment is using the <code>latest</code> image. You may want to explicitly set the tag, e.g.</p> <pre><code>image: vabene1111/recipes:1.4.7\n</code></pre> <p>It is extremely important to use the same image in both the initialization <code>init-chmod-data</code> and the main <code>recipes</code> containers.</p>"},{"location":"install/kubernetes/#60-serviceyaml","title":"60-service.yaml","text":"<p>Creating the app service.</p>"},{"location":"install/kubernetes/#70-ingressyaml","title":"70-ingress.yaml","text":"<p>Setting up the ingress for the recipes service. Requests for static content <code>/static</code> and <code>/media</code> are send to the nginx container, everything else to gunicorn. TLS setup via cert-manager is prepared. You have to change the host from <code>recipes.local</code> to your specific domain.</p>"},{"location":"install/kubernetes/#conclusion","title":"Conclusion","text":"<p>All in all:</p> <ul> <li>The database is set up as a stateful set.</li> <li>The database container runs as a low privileged user.</li> <li>Database and application use secrets.</li> <li>The application also runs as a low privileged user.</li> <li>nginx runs as root but forks children with a low privileged user.</li> <li>There's an ingress rule to access the application from outside.</li> </ul> <p>I tried the setup with kind and it runs well on my local cluster.</p> <p>There is a warning, when you check your system as super user:</p> <p>Media Serving Warning</p> <p>Serving media files directly using gunicorn/python is not recommend! Please follow the steps described here to update your installation.</p> <p>I don't know how this check works, but this warning is simply wrong! ;-) Media and static files are routed by ingress to the nginx container - I promise :-)</p>"},{"location":"install/kubernetes/#updates","title":"Updates","text":"<p>These manifests have been tested for several releases. Newer versions may not work without changes.</p> <p>If everything works as expected, the <code>init-chmod-data</code> initialization container performs the database migration and the update procedure is transparent. However, it is recommended to use specific tags to increase stability and avoid unnecessary migrations.</p>"},{"location":"install/kubernetes/#apply-the-manifets","title":"Apply the manifets","text":"<p>To apply the manifest with kubectl, use the following command:</p> <pre><code>kubectl apply -f ./docs/install/k8s/\n</code></pre>"},{"location":"install/kubesail/","title":"KubeSail or PiBox","text":"<p>Community Contributed</p> <p>This guide was contributed by the community and is neither officially supported, nor updated or tested.</p> <p>KubeSail lets you install Tandoor by providing a simple web interface for installing and managing apps. You can connect any server running Kubernetes, or get a pre-configured PiBox.</p> <p>The KubeSail template is closely based on the Kubernetes installation configs</p>"},{"location":"install/kubesail/#quick-start","title":"Quick Start","text":"<p>Load the Tandoor Recipes template, and click Launch Template.</p> <p>If you have not yet attached your server to KubeSail, see the Getting a Cluster section on the KubeSail docs.</p>"},{"location":"install/kubesail/#important-notes","title":"Important notes","text":"<p>In the \"Template Variables\" section you will see two input fields. These should show <code>RANDOM(16)</code>, indicating they will be randomly generated and specific to your install when you launch the template. If you prefer to set these yourself, you can type them in before launching the template.</p> <p></p>"},{"location":"install/manual/","title":"Manual installation instructions","text":"<p>These instructions are inspired from a standard django/gunicorn/postgresql instructions (for example)</p> <p>Warning</p> <p>Be sure to use python 3.9 at least and pip related to python 3.9 at least. Depending on your distribution calling <code>python</code> or <code>pip</code> will use python2 instead of python 3.9. As of writing this documentation 3.10 is available as well. Make sure your machine got at least 2048 MB memory, otherwise the yarn build will fail with <code>FATAL ERROR: Reached heap limit Allocation failed - JavaScript heap out of memory</code>.</p>"},{"location":"install/manual/#prerequisites","title":"Prerequisites","text":"<p>Setup user: <code>sudo useradd recipes</code></p> <p>Update the repositories and upgrade your OS: <code>sudo apt update &amp;&amp; sudo apt upgrade -y</code></p> <p>Install all prerequisits <code>sudo apt install -y git curl python3 python3-pip python3-venv nginx</code></p> <p>Get the last version from the repository: <code>git clone https://github.com/vabene1111/recipes.git -b master</code></p> <p>Move it to the <code>/var/www</code> directory: <code>mv recipes /var/www</code></p> <p>Change to the directory: <code>cd /var/www/recipes</code></p> <p>Give the user permissions: <code>chown -R recipes:www-data /var/www/recipes</code></p> <p>Create virtual env: <code>python3 -m venv /var/www/recipes</code></p> <p>Install Javascript Tools (nodejs &gt;= 12 required) <pre><code>### Just use one of these possibilites!\n# Using Ubuntu\ncurl -fsSL https://deb.nodesource.com/setup_lts.x | sudo -E bash -\nsudo apt install -y nodejs\n\n# Using Debian, as root\ncurl -fsSL https://deb.nodesource.com/setup_lts.x | bash -\napt install -y nodejs\n\n# Using a RPM based distro\n## ... as root\ncurl -fsSL https://rpm.nodesource.com/setup_lts.x | bash -\n\n## ... no root privileges\ncurl -fsSL https://rpm.nodesource.com/setup_lts.x | sudo bash -\n</code></pre> <pre><code>sudo npm install --global yarn\n</code></pre></p> <p>NodeJS installation issues</p> <p>If you run into problems with the NodeJS installation, please refer to the official documentation.</p>"},{"location":"install/manual/#install-postgresql-requirements","title":"Install postgresql requirements","text":"<pre><code>sudo apt install -y libpq-dev postgresql\n</code></pre>"},{"location":"install/manual/#install-ldap-requirements","title":"Install LDAP requirements","text":"<pre><code>sudo apt install -y libsasl2-dev python3-dev libldap2-dev libssl-dev\n</code></pre>"},{"location":"install/manual/#install-project-requirements","title":"Install project requirements","text":"<p>Update</p> <p>Dependencies change with most updates so the following steps need to be re-run with every update or else the application might stop working. See section Updating below.</p> <p>Using binaries from the virtual env:</p> <pre><code>/var/www/recipes/bin/pip3 install -r requirements.txt\n</code></pre> <p>You will also need to install front end requirements and build them. For this navigate to the <code>./vue</code> folder and run</p> <pre><code>cd ./vue\nyarn install\nyarn build\n</code></pre>"},{"location":"install/manual/#setup-postgresql","title":"Setup postgresql","text":"<pre><code>sudo -u postgres psql\n</code></pre> <p>In the psql console:</p> <pre><code>CREATE DATABASE djangodb;\nCREATE USER djangouser WITH PASSWORD 'password';\nGRANT ALL PRIVILEGES ON DATABASE djangodb TO djangouser;\nALTER DATABASE djangodb OWNER TO djangouser;\n\n--Maybe not necessary, but should be faster:\nALTER ROLE djangouser SET client_encoding TO 'utf8';\nALTER ROLE djangouser SET default_transaction_isolation TO 'read committed';\nALTER ROLE djangouser SET timezone TO 'UTC';\n\n--Grant superuser right to your new user, it will be removed later\nALTER USER djangouser WITH SUPERUSER;\n\n--exit Postgres Environment\nexit\n</code></pre> <p>Download the <code>.env</code> configuration file and edit it accordingly. <pre><code>wget https://raw.githubusercontent.com/vabene1111/recipes/develop/.env.template -O /var/www/recipes/.env\n</code></pre></p> <p>Things to edit:</p> <ul> <li><code>SECRET_KEY</code>: use something secure (generate it with <code>base64 /dev/urandom | head -c50</code> f.e.).</li> <li><code>POSTGRES_HOST</code>: probably 127.0.0.1.</li> <li><code>POSTGRES_PASSWORD</code>: the password we set earlier when setting up djangodb.</li> <li><code>STATIC_URL</code>, <code>MEDIA_URL</code>: these will be in <code>/var/www/recipes</code>, under <code>/staticfiles/</code> and <code>/mediafiles/</code> respectively.</li> </ul>"},{"location":"install/manual/#initialize-the-application","title":"Initialize the application","text":"<p>Execute <code>export $(cat /var/www/recipes/.env |grep \"^[^#]\" | xargs)</code> to load variables from <code>/var/www/recipes/.env</code></p> <p>Execute <code>bin/python3 manage.py migrate</code></p> <p>and revert superuser from postgres:</p> <pre><code>sudo -u postgres psql` and `ALTER USER djangouser WITH NOSUPERUSER;\nexit\n</code></pre> <p>Generate static files: <code>bin/python3 manage.py collectstatic --no-input</code> and <code>bin/python3 manage.py collectstatic_js_reverse</code> and remember the folder where files have been copied.</p>"},{"location":"install/manual/#setup-web-services","title":"Setup web services","text":""},{"location":"install/manual/#gunicorn","title":"gunicorn","text":"<p>Create a service that will start gunicorn at boot: <code>sudo nano /etc/systemd/system/gunicorn_recipes.service</code></p> <p>And enter these lines:</p> <pre><code>[Unit]\nDescription=gunicorn daemon for recipes\nAfter=network.target\n\n[Service]\nType=simple\nRestart=always\nRestartSec=3\nUser=recipes\nGroup=www-data\nWorkingDirectory=/var/www/recipes\nEnvironmentFile=/var/www/recipes/.env\nExecStart=/var/www/recipes/bin/gunicorn --error-logfile /tmp/gunicorn_err.log --log-level debug --capture-output --bind unix:/var/www/recipes/recipes.sock recipes.wsgi:application\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Note: <code>-error-logfile /tmp/gunicorn_err.log --log-level debug --capture-output</code> are useful for debugging and can be removed later</p> <p>Note2: Fix the path in the <code>ExecStart</code> line to where you gunicorn and recipes are</p> <p>Finally, run <code>sudo systemctl enable --now gunicorn_recipes</code>. You can check that the service is correctly started with <code>systemctl status gunicorn_recipes</code></p>"},{"location":"install/manual/#nginx","title":"nginx","text":"<p>Now we tell nginx to listen to a new port and forward that to gunicorn. <code>sudo nano /etc/nginx/conf.d/recipes.conf</code></p> <p>And enter these lines:</p> <pre><code>server {\nlisten 8002;\n#access_log /var/log/nginx/access.log;\n#error_log /var/log/nginx/error.log;\n\n# serve media files\nlocation /static/ {\nalias /var/www/recipes/staticfiles;\n}\n\nlocation /media/ {\nalias /var/www/recipes/mediafiles;\n}\n\nlocation / {\nproxy_set_header Host $http_host;\nproxy_pass http://unix:/var/www/recipes/recipes.sock;\nproxy_set_header X-Forwarded-Proto $scheme;\n}\n}\n</code></pre> <p>Note: Enter the correct path in static and proxy_pass lines.</p> <p>Reload nginx : <code>sudo systemctl reload nginx</code></p>"},{"location":"install/manual/#updating","title":"Updating","text":"<p>In order to update the application you will need to run the following commands (probably best to put them into a small script).</p> <pre><code># change directory\ncd /var/www/recipes\n# Update source files\ngit pull\n# load envirtonment variables\nexport $(cat /var/www/recipes/.env |grep \"^[^#]\" | xargs)\n#install project requirements\nbin/pip3 install -r requirements.txt\n# migrate database \nbin/python3 manage.py migrate\n# collect static files\n# if the output is not \"0 static files copied\" you might want to run the commands again to make sure everythig is collected\nbin/python3 manage.py collectstatic --no-input\nbin/python3 manage.py collectstatic_js_reverse\n# change to frontend directory\ncd vue\n# install and build frontend\nyarn install\nyarn build\n# restart gunicorn service\nsudo systemctl restart gunicorn_recipes\n</code></pre>"},{"location":"install/other/","title":"Other setups","text":"<p>Community Contributed</p> <p>The examples in this section were contributed by members of the community. This page especially contains some setups that might help you if you really want to go down a certain path but none of the examples are supported (as I simply am not able to give you support for them).</p>"},{"location":"install/other/#apache-traefik-sub-path","title":"Apache + Traefik + Sub-Path","text":"<p>This guide was contributes by incaseoftrouble in Issue #266</p> <p>My setup is docker-compose / traefik / apache / recipes. Swapping out apache for nginx should be straightforward.</p> <p>Relevant parts:</p> <p>docker-compose: <pre><code>  apache:\n# omitting other config\nvolumes:\n- ./recipes/static:/var/www/recipes/static:ro\n- ./recipes/media:/var/www/recipes/media:ro\nlabels:\ntraefik.enable: true\ntraefik.http.routers.apache-recipes.rule: Host(`&lt;host&gt;`) &amp;&amp; PathPrefix(`/&lt;www path&gt;`)\ntraefik.http.routers.apache-recipes.entrypoints: http\ntraefik.http.routers.apache-recipes.service: apache\ntraefik.http.services.apache.loadbalancer.server.port: 80\ntraefik.http.services.apache.loadbalancer.server.scheme: http\n...\n\nrecipes:\nvolumes:\n- ./recipes/static:/opt/recipes/staticfiles:rw\n- ./recipes/media:/opt/recipes/mediafiles:rw\nenvironment:\n# all the other env\n- SCRIPT_NAME=/&lt;sub path&gt;\n- JS_REVERSE_SCRIPT_PREFIX=/&lt;sub path&gt;/\n- STATIC_URL=/&lt;www path&gt;/static/\n- MEDIA_URL=/&lt;www path&gt;/media/\nlabels:\ntraefik.enable: true\ntraefik.http.routers.recipes.rule: Host(`&lt;host&gt;`) &amp;&amp; PathPrefix(`/&lt;sub path&gt;`)\ntraefik.http.routers.recipes.entrypoints: http\ntraefik.http.services.recipes.loadbalancer.server.port: 8080\ntraefik.http.services.recipes.loadbalancer.server.scheme: http\n</code></pre></p> <p>apache:  <pre><code>  Alias /&lt;www path&gt;/static/ /var/www/recipes/static/\n  Alias /&lt;www path&gt;/media/ /var/www/recipes/media/\n  &lt;Directory \"/var/www/recipes/\"&gt;\n    Require all granted\n  &lt;/Directory&gt;\n</code></pre></p> <p>I used two paths <code>&lt;sub path&gt;</code> and <code>&lt;www path&gt;</code> for simplicity. In my case I have <code>&lt;sub path&gt; = recipes</code> and <code>&lt;www path&gt; = serve/recipes</code>. One could also change the matching rules of traefik to have everything under one path.</p> <p>I left out the TLS config in this example for simplicity.</p>"},{"location":"install/other/#wsl","title":"WSL","text":"<p>If you want to install Tandoor on the Windows Subsystem for Linux you can find a detailed post here: https://github.com/TandoorRecipes/recipes/issues/1733.</p>"},{"location":"install/swag/","title":"Swag","text":"<p>Danger<p>Please refer to the official documentation for the container setup. This example shows just one setup that may or may not differ from yours in significant ways. This tutorial does not cover security measures, backups, and many other things that you might want to consider.</p> </p>"},{"location":"install/swag/#prerequisites","title":"Prerequisites","text":"<ul> <li>You have a newly spun-up Ubuntu server with docker (pre-)installed.</li> <li>At least one <code>mydomain.com</code> and one <code>mysubdomain.mydomain.com</code> are pointing to the server's IP. (This tutorial does not cover subfolder installation.)</li> <li>You have an ssh terminal session open.</li> </ul>"},{"location":"install/swag/#installation","title":"Installation","text":""},{"location":"install/swag/#download-and-edit-tandoor-configuration","title":"Download and edit Tandoor configuration","text":"<p><pre><code>cd /opt\nmkdir recipes\ncd recipes\nwget https://raw.githubusercontent.com/vabene1111/recipes/develop/.env.template -O .env\nbase64 /dev/urandom | head -c50\n</code></pre> Copy the response from that last command and paste the key into the <code>.env</code> file: <pre><code>nano .env\n</code></pre> You'll also need to enter a Postgres password into the <code>.env</code> file. Then, save the file and exit the editor.</p>"},{"location":"install/swag/#install-and-configure-docker-compose","title":"Install and configure Docker Compose","text":"<p>In keeping with these instructions: <pre><code>cd /opt\ncurl -L --fail https://raw.githubusercontent.com/linuxserver/docker-docker-compose/master/run.sh -o /usr/local/bin/docker-compose\nchmod +x /usr/local/bin/docker-compose\n</code></pre></p> <p>Next, create and edit the docker compose file.</p> <pre><code>nano docker-compose.yml\n</code></pre> <p>Paste the following and adjust your domains, subdomains and time zone.</p> <pre><code>---\nversion: \"2.1\"\nservices:\n  swag:\n    image: ghcr.io/linuxserver/swag\n    container_name: swag\n    cap_add:\n      - NET_ADMIN\n    environment:\n      - PUID=1000\n      - PGID=1000\n      - TZ=Europe/Berlin # &lt;---- EDIT THIS &lt;----  &lt;---- \n      - URL=mydomain.com # &lt;---- EDIT THIS &lt;----  &lt;---- \n      - SUBDOMAINS=mysubdomain,myothersubdomain # &lt;---- EDIT THIS &lt;----  &lt;---- \n      - EXTRA_DOMAINS=myotherdomain.com # &lt;---- EDIT THIS &lt;----  &lt;---- \n      - VALIDATION=http\n    volumes:\n      - ./swag:/config\n      - ./recipes/media:/media\n    ports:\n      - 443:443\n      - 80:80\n    restart: unless-stopped\n\n  db_recipes:\n    restart: always\n    container_name: db_recipes\n    image: postgres:15-alpine\n    volumes:\n      - ./recipes/db:/var/lib/postgresql/data\n    env_file:\n      - ./recipes/.env\n\n  recipes:\n    image: vabene1111/recipes\n    container_name: recipes\n    restart: unless-stopped\n    env_file:\n      - ./recipes/.env\n    environment:\n      - UID=1000\n      - GID=1000\n      - TZ=Europe/Berlin # &lt;---- EDIT THIS  &lt;----  &lt;---- \n    volumes:\n      - ./recipes/static:/opt/recipes/staticfiles\n      - ./recipes/media:/opt/recipes/mediafiles\n    depends_on:\n      - db_recipes\n</code></pre> <p>Save and exit.</p>"},{"location":"install/swag/#create-containers-and-configure-swag-reverse-proxy","title":"Create containers and configure swag reverse proxy","text":"<pre><code>docker-compose up -d\n</code></pre> <pre><code>cd /opt/swag/nginx/proxy-confs\ncp recipes.subdomain.conf.sample recipes.subdomain.conf\nnano recipes.subdomain.conf\n</code></pre> <p>Change the line <code>server_name recipes.*;</code> to <code>server_name mysubdomain.*;</code>, save and exit.</p>"},{"location":"install/swag/#finalize","title":"Finalize","text":"<pre><code>cd /opt\ndocker restart swag recipes\n</code></pre> <p>Go to <code>https://mysubdomain.mydomain.com</code>. (If you get a \"502 Bad Gateway\" error, be patient. It might take a short while until it's functional.)</p>"},{"location":"install/synology/","title":"Synology","text":"<p>Community Contributed</p> <p>This guide was contributed by the community and is neither officially supported, nor updated or tested.</p> <p>Many people appear to host this application on their Synology NAS. The following documentation was provided by  @therealschimmi in this issue discussion.</p> <p>There is also this  (word,  pdf) awesome and  very detailed guide provided by @DiversityBug.</p> <p>There are, as always, most likely other ways to do this but this can be used as a starting point for your  setup. Since I cannot test it myself feedback and improvements are always very welcome.</p>"},{"location":"install/synology/#instructions","title":"Instructions","text":"<p>Basic guide to setup <code>vabenee1111/recipes</code> docker container on Synology NAS.</p>"},{"location":"install/synology/#1-login-to-synology-dsm-through-your-browser","title":"1. Login to Synology DSM through your browser","text":"<ul> <li>Install Docker through package center</li> <li>Optional: Create a shared folder for your docker projects, they have to store data somewhere outside the containers</li> <li>Create a folder somewhere, I suggest naming it 'recipes' and storing it in the dedicated docker folder</li> <li>Within, create the necessary folder structure. You will need these folders:</li> </ul>"},{"location":"install/synology/#2-download-templates","title":"2. Download templates","text":"<p>Info</p> <p>vabene1111 gives you a few samples for various setups to work with. I chose to use the plain setup for now.</p> <ul> <li>Open https://github.com/vabene1111/recipes/tree/develop/docs/install/docker (link)</li> <li>Download docker-compose.yml to your recipes folder (direct link to plain)</li> <li>Open https://github.com/vabene1111/recipes/tree/develop/nginx/conf.d (link)</li> <li>Download Recipes.conf to your conf.d folder (direct link)</li> <li>Open https://github.com/vabene1111/recipes/blob/develop/.env.template (link)</li> <li>Copy the text and save it as <code>.env</code> to your recipes folder (no filename extension!)</li> <li>Add a <code>POSTGRES_PASSWORD</code></li> <li>Once done, it should look like this:</li> </ul> <p></p>"},{"location":"install/synology/#3-edit-docker-composeyml","title":"3. Edit docker-compose.yml","text":"<ul> <li>Open docker-compose.yml in a text editor</li> <li>This file tells docker how to setup recipes. Docker will create three containers for recipes to work, recipes, nginx and postgresql. They are all required and need to store and share data through the folders you created before.</li> <li>Edit line 26, this line specifies which external synology port will point to which internal docker port. Chose a free port to use and replace the first number with it. You will open recipes by browsing to http://your.synology.ip:chosen.port, e.g. http://192.168.1.1:2000</li> <li>If you want to use port 2000 you would edit to 2000:80</li> </ul>"},{"location":"install/synology/#4-ssh-into-your-synology","title":"4. SSH into your Synology","text":"<ul> <li>You need to access your Synology through SSH </li> <li>Execute following commands</li> <li><code>ssh root@your.synology.ip</code>   connect to your synology. root password is the same as admin password, sometimes root access is not possible for whatever reason, then replace root with admin</li> <li><code>cd /volume1/docker/recipes</code>  access the folder where you store docker-compose.yml</li> <li><code>docker-compose up -d</code>        this starts your containers according to your docker-compose.yml. if you logged in with admin you will have to use  <code>sudo docker-compose up -d</code> instead, it will ask for the admin password again. </li> <li>This output tells you all 3 containers have been setup <pre><code>...\nCreating recipes_nginx_recipes_1 ... done\nCreating recipes_db_recipes_1    ... done\nCreating recipes_web_recipes_1   ... done\n</code></pre></li> <li>Browse to 192.168.1.1:2000 or whatever your IP and port are</li> <li>While the containers are starting and doing whatever they need to do, you might still get HTTP errors e.g. 500 or 502. Just be patient and try again in a moment</li> </ul>"},{"location":"install/synology/#5-firewall","title":"5. Firewall","text":"<p>You need to set up firewall rules in order for the recipes_web container to be able to connect to the recipes_db container.</p> <ul> <li>Control Panel -&gt; Security -&gt; Firewall -&gt; Edit Rules -&gt; Create<ul> <li>Ports: All</li> <li>Source IP: Specific IP -&gt; Select -&gt; Subnet<ul> <li>insert docker network ip (can be found in the docker application, network tab)</li> <li>Example: IP address: 172.18.0.0 and Subnet mask/Prefix length: 255.255.255.0</li> </ul> </li> <li>Action: Allow</li> </ul> </li> <li>Save and make sure it's above the deny rules</li> </ul>"},{"location":"install/synology/#6-additional-ssl-setup","title":"6. Additional SSL Setup","text":"<p>Easiest way is to do it via Reverse Proxy.</p> <ul> <li>Control Panel -&gt; Login Portal (renamed Since DSM 7, previously Application Portal) -&gt; Advanced -&gt; Reverse Proxy</li> <li>Create<ul> <li>insert name</li> <li>Source:<ul> <li>Protocol: HTTPS</li> <li>Hostname: URL if you access from outside, otherwise ip in network</li> <li>Port: The port you want to access, has to be a different one that the one in the docker-compose file</li> <li>HSTS can be enabled</li> </ul> </li> <li>Destination:<ul> <li>Protocol: HTTP</li> <li>Hostname: localhost</li> <li>Port: port in docker-compose file</li> </ul> </li> <li>Click on Custom Header and press Create -&gt; Websocket</li> <li>Save</li> </ul> </li> <li>Control Panel -&gt; Security -&gt; Firewall -&gt; Edit Rules -&gt; Create<ul> <li>Ports: Select form a list of built-in applications -&gt; Select -&gt; You find your Reverse Proxy, enable it</li> <li>Source IP: Depends, All allows access from outside, i use specific to only connect in my network</li> <li>Action: Allow</li> </ul> </li> <li>Save and make sure it's above the deny rules</li> </ul> <p>[Deprecated, Note: ssl Path changed for DSM 7] 6.1 Additional SSL Setup  - create folder <code>ssl</code> inside <code>nginx</code> folder     - download your ssl certificate from <code>security</code> tab in dsm <code>control panel</code>     - or create a task in <code>task manager</code> because Synology will update the certificate every few months         - set task to repeat every day         - in the script write:         <pre><code>SRC=\"/usr/syno/etc/certificate/system/default\"\nDEST=\"/volume1/docker/recipes/nginx/ssl/\"\nif [ ! -f \"$DEST/fullchain.pem\" ] || [ \"$SRC/fullchain.pem\" -nt \"$DEST/fullchain.pem\" ]; then\ncp \"$SRC/fullchain.pem\" \"$DEST/\"\ncp \"$SRC/privkey.pem\" \"$DEST/\"\nchown root:root \"$DEST/fullchain.pem\" \"$DEST/privkey.pem\"\nchmod 600 \"$DEST/fullchain.pem\" \"$DEST/privkey.pem\"\n/usr/syno/bin/synowebapi --exec api=SYNO.Docker.Container version=1 method=restart name=recipes_nginx_recipes_1\nfi\n</code></pre> - change <code>docker-compose.yml</code>   add <code>- ./nginx/ssl:/etc/nginx/certs</code> to the <code>volumes</code> of <code>nginx_recipes</code></p>"},{"location":"install/traefik/","title":"Traefik","text":"<p>Danger</p> <p>Please refer to the official documentation. This example just shows something similar to my setup in case you dont understand the official documentation.</p> <p>You need to create a network called <code>traefik</code> using <code>docker network create traefik</code>.</p>"},{"location":"install/traefik/#docker-composeyml","title":"docker-compose.yml","text":"<pre><code>version: \"3.3\"\n\nservices:\n\n  traefik:\n    image: \"traefik:v2.1\"\n    container_name: \"traefik\"\n    ports:\n      - \"443:443\"\n      - \"80:80\"\n      - \"8080:8080\"\n    volumes:\n      - \"./letsencrypt:/letsencrypt\"\n      - \"/var/run/docker.sock:/var/run/docker.sock:ro\"\n      - \"./config:/etc/traefik/\"\n\n\nnetworks:\n    default:\n       external:\n         name: traefik\n</code></pre>"},{"location":"install/traefik/#traefiktoml","title":"traefik.toml","text":"<p>Place this in a directory called <code>config</code> as this is mounted into the traefik container (see docer compose). Change the email address accordingly. <pre><code>[api]\n  insecure=true\n\n[providers.docker]\n  endpoint = \"unix:///var/run/docker.sock\"\n  exposedByDefault = false\n  network = \"traefik\"\n\n#[log]\n#  level = \"DEBUG\"\n\n[entryPoints]\n  [entryPoints.web]\n    address = \":80\"\n\n  [entryPoints.web_secure]\n    address = \":443\"\n\n[certificatesResolvers.le_resolver.acme]\n\n  email = \"you_email@mail.com\"\n  storage = \"/letsencrypt/acme.json\"\n\n  tlsChallenge=true\n</code></pre></p>"},{"location":"install/truenas_portainer/","title":"TrueNAS Portainer","text":"<p>Community Contributed</p> <p>This guide was contributed by the community and is neither officially supported, nor updated or tested.</p> <p>This guide is to assist those installing Tandoor Recipes on Truenas Core using Docker and or Portainer</p> <p>Docker install instructions adapted from PhasedLogix IT Services's guide. Portainer install instructions adopted from the Portainer Official Documentation. Tandoor installation on Portainer provided by users <code>Szeraax</code> and <code>TransatlanticFoe</code> on Discord (Thank you two!)</p>"},{"location":"install/truenas_portainer/#instructions","title":"Instructions","text":"<p>Basic guide to setup Docker and Portainer TrueNAS Core.</p>"},{"location":"install/truenas_portainer/#1-login-to-truenas-through-your-browser","title":"1. Login to TrueNAS through your browser","text":"<ul> <li>Go to the Virtual Machines Menu ![Screenshot of TrueNAS VM Menu[(https://d33wubrfki0l68.cloudfront.net/e5bc016268e41fadea77fd91a35c40d52280d221/c9daf/images/blog/truenasvmpage.png)</li> <li>Click Add to add a new virtual machine. You will want the following settings:     -Guest operating system: Linux     -Name: UBUDocker (or whatever you want it to be)     -System Clock: Local     -Boot method: UEFI     -Shutdown time: 90     -Start on boot enabled     -Enable VNC enabled </li> <li>Click next to dedicate resources to the VM (see below image of authors setup, you may need to change resources to fit your needs) </li> <li>Hit next to go to disk setup     -You want to create a new disk, here are the settings you should use     -Disk Type: AHCI     -Zvol location: tank/vm (Or wherever you have your VM memory located at)     -Size: Atleast 30 gigs  -Hit next to go to network interface (The defaults are fine but make sure you select the right network adapter) -Hit next to go to installation     -Navigate to your ubuntu ISO file (The original author and this author used Ubuntu Server. This OS uses less resources than some other OS's and can be ran Headless with either VNC or SSH access. You can use other OS's, but this guide was written with Ubuntu Server) -Hit next, then submit, you have made the virtual machine!     -Open the virtual machine then hit VNC to open ubuntu  -Once its up choose your language and go through the installer     -Once you are done with the setup we want to SSH into the ubuntu VM to setup docker     -Open powershell and type SSH \"user\"@(ip) (replace \"user\" with the user you setup in the OS installation)     -Enter your Password if requested     -Close the VNC Console     -Go back into the SSH console and get ready to type some commands. Type these commands in order:     <code>sudo apt update</code> <code>sudo apt install apt-transport-https ca-certificates curl software-properties-common</code> <code>y</code> (If prompted with a question)     <code>curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -</code> <code>sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu focal stable\"</code> <code>sudo apt update</code> <code>apt-cache policy docker-ce</code>     -To make it so you don\u2019t have to use sudo for every docker command run this command     <code>sudo usermod -aG docker ${USER}</code> <code>su - ${USER}</code></li> </ul>"},{"location":"install/truenas_portainer/#2-install-portainer","title":"2. Install Portainer","text":"<p>!!! Note: By default, Portainer Server will expose the UI over port 9443 and expose a TCP tunnel server over port 8000. The latter is optional and is only required if you plan to use the Edge compute features with Edge agents.</p> <p>-First, create the volume that Portainer Server will use to store its database: <code>docker volume create portainer_data</code> -Then, download and install the Portainer Server container: <code>docker run -d -p 8000:8000 -p 9443:9443 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:latest</code> -Portainer Server has now been installed. You can check to see whether the Portainer Server container has started by running <code>docker ps</code> -Now that the installation is complete, you can log into your Portainer Server instance by opening a web browser and going to:     <code>https://localhost:9443</code>     -Replace <code>localhost</code> with the relevant IP address or FQDN if needed, and adjust the port if you changed it earlier. -You will be presented with the initial setup page for Portainer Server. -Create your first user     -Your first user will be an administrator. The username defaults to admin but you can change it if you prefer. The password must be at least 12 characters long and meet the listed password requirements. -Connect Portainer to your environments.     -Once the admin user has been created, the \"Environment Wizard\" will automatically launch. The wizard will help get you started with Portainer.     -Select \"Get Started\" to use the Enviroment Portainer is running in </p>"},{"location":"install/truenas_portainer/#3-install-tandoor-recipies-via-portainer-web-editor","title":"3. Install Tandoor Recipies VIA Portainer Web Editor","text":"<p>-From the menu select Stacks, click Add stack, give the stack a descriptive name then select Web editor.  -Use the below code and input it into the Web Editor:</p> <p>`version: \"3\" services:   db_recipes:     restart: always     image: postgres:15-alpine     volumes:       - ./postgresql:/var/lib/postgresql/data     env_file:       - stack.env</p> <p>web_recipes:</p>"},{"location":"install/truenas_portainer/#image-vabene1111recipeslatest","title":"image: vabene1111/recipes:latest","text":"<pre><code>image: vabene1111/recipes:beta\nenv_file:\n  - stack.env\nvolumes:\n  - staticfiles:/opt/recipes/staticfiles\n  # Do not make this a bind mount, see https://docs.tandoor.dev/install/docker/#volumes-vs-bind-mounts\n  - nginx_config:/opt/recipes/nginx/conf.d \n  - ./mediafiles:/opt/recipes/mediafiles\ndepends_on:\n  - db_recipes\n</code></pre> <p>nginx_recipes:     image: nginx:mainline-alpine     restart: always     ports:       - 12008:80     env_file:       - stack.env     depends_on:       - web_recipes     volumes:       # Do not make this a bind mount, see https://docs.tandoor.dev/install/docker/#volumes-vs-bind-mounts       - nginx_config:/etc/nginx/conf.d:ro       - staticfiles:/static       - ./mediafiles:/media</p> <p>volumes:   nginx_config:   staticfiles:`</p> <p>-Download the .env template from HERE and load this file by pressing the \"Load Variables from .env File\" button: </p> <p>-You will need to change the following variables:     -<code>SECRET_KEY</code> needs to be replaced with a new key. This can be generated from websites like Djecrety     -<code>TIMEZONE</code> needs to be replaced with the appropriate code for your timezone. Accepted values can be found at TimezoneDB     -<code>POSTGRES_USER</code> and <code>POSTGRES_PASSWORD</code> needs to be replaced with your username and password from PostgreSQL !!!NOTE Do not sign in using social media. You need to sign up using Email and Password. -After those veriables are changed, you may press the <code>Deploy the Stack</code> button at the bottom of the page. This will create the needed containers to run Tandoor Recipes.</p>"},{"location":"install/truenas_portainer/#4-login-and-setup-your-new-server","title":"4. Login and Setup your new server!","text":"<ul> <li>You need to access your Tandoor Server through its Webpage: <code>https://localhost:xxxx</code> replacing <code>localhost</code> with the IP of the VM running Docker and <code>xxxx</code> with the port you chose in the Web Editor for <code>nginx_recipes</code> above. In this case, <code>12008</code>.  !!! While the containers are starting and doing whatever they need to do, you might still get HTTP errors e.g. 500 or 502. Just be patient and try again in a moment -You will now need to set up the Tandoor Server through the WebGUI.</li> </ul>"},{"location":"install/unraid/","title":"Unraid","text":"<p>Community Contributed</p> <p>This guide was contributed by the community and is neither officially supported, nor updated or tested.</p> <p>Unraid is an operating system that allows you to easily install and setup applications.</p> <p>Thanks to CorneliousJD this application can easily be installed using unraid. Please view Issue #184 for further details. There is also a discussion thread on the  unraid forum where he gives additional information.</p>"},{"location":"install/unraid/#installation","title":"Installation","text":""},{"location":"install/unraid/#install-community-applications","title":"Install Community Applications","text":"<p>Tandoor for unRAID is available via <code>Community Applications</code>. You will first need to install <code>Community Applications (CA)</code> by following the directions here: Unraid forums</p>"},{"location":"install/unraid/#locate-and-install-tandoor-recipes","title":"Locate and install Tandoor Recipes","text":"<p>After that, you can go to the \"Apps\" tab in unRAID and search for <code>Tandoor Recipes</code>, locate the correct container and install it.  </p>"},{"location":"install/unraid/#configure-settings","title":"Configure settings","text":"<p>The default settings should be fine for most users, just be sure to enter a secret key that is randomly generated. Then click <code>Apply</code>. </p>"},{"location":"install/unraid/#access-website","title":"Access website","text":"<p>After the container is installed, click on the <code>Tandoor Recipes</code> icon and click the WebUI button to launch the web user interface. Set the container to auto-start if you wish.  </p>"},{"location":"install/wsl/","title":"Ubuntu Installation on Windows (WSL) and Docker Desktop","text":"<p>Install Docker from https://docs.docker.com/desktop/install/windows-install/ Be sure to select the Use WSL 2 instead of Hyper-V option on the configuration page when prompted</p> <p>Follow the instructions to install Tandoor on Docker. Tandoor installation instructions using Docker is gotten from https://docs.tandoor.dev/install/docker/</p> <p>You may get the error below if you are using Docker Desktop: /usr/bin/docker-credential-desktop.exe: Invalid argument</p> <p>This indicates that Docker Compose is not able to pull authentication credentials that are needed to pull recipe files.</p> <p>Run the command: export DOCKER_CONFIG=/non-existent-directory</p> <p>\"non-existent-directory\" could be an arbitrary directory of your choosing. It could be empty, we are just giving docker a file to point to. You can create a credentials file at a later date to add security to your application.</p> <p>After you run the command docker-compose up -d, you may encounter an error similar to the one below: fixing permissions on existing directory /var/lib/postgresql/data ... 2023-03-01T15:38:27.140501700Z chmod: /var/lib/postgresql/data: Operation not permitted</p> <p>This indicates that the postgresql user 'postgres' does not have the necessary permissions to  change the permissions of the /var/lib/postgresql/data directory. Note: This issue does not occuer in the Powershell terminal, so it might be easier to install Tandoor in powershell and continue development using WSL. Steps to fix this error: Since the permissions have to be changed within the docker container, we will need to create a file that runs as soon as the container starts up. This container will change the permissions of the /var/lib/postgresql/data directory before the db_recipes-1 container is started up. This container sets up the database to accept connections. Docker allows us to set up an entrypoint in the docker-compose.yml file. This is where we will set the commands to change the permissions of the postgres user. Steps to set up entry-point file: 1.  Create a new file \u2018docker-entrypoint.sh\u2019 in the same directory as your docker-compose.yml file. This will be a bash file. 2.  Add the following commands to the file a.  #!/bin/sh (This is called a shebang. It tells the OS the shell to use which is the sh shell in this case) b.  chmod 777 /var/lib/postgresql/data (Gives read, write and execute permissions on the directory to all users, you may change these permissions as you wish) c.  exec \u201c@\u201d (Runs the script with the commands above)</p> <p>Your folder structure should look like this with docker-compose.yml and docker-entrypoint.sh in the same directory: </p> <p>The docker-entrypoint.sh file should look like this: </p> <ol> <li>Open the docker-compose.yml file</li> <li>Add an entrypoint configuration to the db_recipes service entrypoint:</li> <li> <p>docker-entrypoint.sh This command makes sure that the docker-entrypoint.sh file is run first before the db_recipes services is started. Using this, we set the database user permission before they are needed, so it gets rid of the error. Your docker-compose.yml file should look like this: </p> </li> <li> <p>Run docker-compose up -d, all the containers should run!</p> </li> </ol>"},{"location":"system/backup/","title":"Backup","text":"<p>There is currently no \"good\" way of backing up your data implemented in the application itself. This mean that you will be responsible for backing up your data.</p> <p>It is planned to add a \"real\" backup feature similar to applications like homeassistant where a snapshot can be downloaded and restored through the web interface.</p> <p>Warning</p> <p>When developing a new backup strategy, make sure to also test the restore process!</p>"},{"location":"system/backup/#database","title":"Database","text":"<p>Please use any standard way of backing up your database. For most systems this can be achieved by using a dump  command that will create an SQL file with all the required data.</p> <p>Please refer to your Database System documentation.</p> <p>I personally use a little script that I have created to automatically pull SQL dumps from a postgresql database. It is neither well tested nor documented so use at your own risk. I would recommend using it only as a starting place for your own backup strategy.</p>"},{"location":"system/backup/#mediafiles","title":"Mediafiles","text":"<p>The only Data this application stores apart from the database are the media files (e.g. images) used in your  recipes.</p> <p>They can be found in the mediafiles mounted directory (depending on your installation).</p> <p>To create a backup of those files simply copy them elsewhere. Do it the other way around for restoring.</p> <p>The filenames consist of <code>&lt;random uuid4&gt;_&lt;recipe_id&gt;</code>. In case you screw up really badly this can help restore data.</p>"},{"location":"system/backup/#manual-backup-from-docker-build","title":"Manual backup from docker build","text":"<p>The standard docker build of tandoor uses postgresql as the back end database. This can be backed up using a function called \"dumpall\". This generates a .SQL file containing a list of commands for a postgresql server to use to rebuild your database. You will also need to back up the media files separately.</p> <p>Making a full copy of the docker directory can work as a back up, but only if you know you will be using the same hardware, os, and postgresql version upon restore. If not, then the different version of postgresql won't be compatible with the existing tables. You can back up from docker even when the tandoor container is failing, so long as the postgresql database has started successfully. When using this backup method, ensure that your recipes have imported successfully. One user reported only the titles and images importing on first try, requiring a second run of the import command.</p> <p>the following commands assume that your docker-compose files are in a folder called \"docker\". replace \"docker_db_recipes_1\" with the name of your db container. The commands also assume you use a backup name of pgdump.sql. It's a good idea to include a date in this filename, so that successive backups do not get deleted. To back up: <pre><code>sudo docker exec -t docker_db_recipes_1 pg_dumpall -U djangouser &gt; pgdump.sql\n</code></pre></p> <p>To restore: <pre><code>cat pgdump.sql | sudo docker exec -i docker_db_recipes_1 psql postgres -U djangouser\n</code></pre> This connects to the postgres table instead of the actual dgangodb table, as the import function needs to delete the table, which can't be dropped off you're connected to it.</p>"},{"location":"system/backup/#backup-using-export-and-import","title":"Backup using export and import","text":"<p>You can now export recipes from Tandoor using the export function. This method requires a working web interface. 1. Click on a recipe 2. Click on the three meatballs then export 3. Select the all recipes toggle and then export. This should download a zip file.</p> <p>Import: Go to Import &gt; from app &gt; tandoor and select the zip file you want to import from.</p>"},{"location":"system/migration_sqlite-postgres/","title":"How to migrate from sqlite3 database to postgresql","text":"<p>This migration was written while using the unraid template (docker) for TandoorRecipes, version 1.3.0. While some commands are unraid specific, it should in general work for any setup.</p> <ol> <li> <p>Make a backup of your <code>/mnt/user/appdata/recipes</code> dir.</p> </li> <li> <p>Without changing any settings, get a shell into the TandoorRecipes docker through the Web-UI or by running <code>docker exec -it TandoorRecipes /bin/sh</code> <pre><code>cd /opt/recipes\n./venv/bin/python manage.py export -a &gt; /data/dump.json\n</code></pre></p> </li> <li> <p>Create a Postgresql database (With a new user &amp; database for recipes)</p> </li> </ol> <p>I used the <code>postgresql14</code> template.</p> <pre><code>psql -U postgres\npostgres=# create database tandoor;\npostgres=# create user tandoor with encrypted password 'yoursupersecretpassworddontusethisone';\npostgres=# grant all privileges on database tandoor to tandoor;\n</code></pre> <ol> <li> <p>Now its time to change some enviourment variables in TandoorRecipes template: <pre><code>DB_ENGINE=django.db.backends.postgresql  # Database Engine, previous value: `django.db.backends.sqlite3`\nPOSTGRES_HOST=&lt;Your unraid host ip&gt;  # PostgreSQL Host\nPOSTGRES_PORT=5432  # PostgreSQL Host\nPOSTGRES_USER=tandoor  # PostgreSQL User\nPOSTGRES_PASSWORD=yoursupersecretpassworddyoudidntcopy  # PostgreSQL Password\nPOSTGRES_DB=tandoor  # Database, previous value: `/data/recipes.db`\n</code></pre></p> </li> <li> <p>Save it, and start the container once.</p> </li> </ol> <p>It will perform all database migrations once for the postgresql database.</p> <ol> <li> <p>Get a shell into the docker through the WEB-UI or by running <code>docker exec -it TandoorRecipes /bin/sh</code> <pre><code>cd /opt/recipes\n./venv/bin/python manage.py import /data/dump.json\n</code></pre></p> </li> <li> <p>Enjoy your new fuzzy search options and SLIGHTLY performance increase!</p> </li> </ol>"},{"location":"system/permissions/","title":"Permission System","text":"<p>WIP</p> <p>This application was developed for private use in a trusted environment. Due to popular demand a basic permission system has been added.  It does its job protecting the most critical parts of the application, but it is not yet recommended to  give accounts to completely untrusted users. Work is done to improve the permission system, but it's not yet fully done and tested.</p>"},{"location":"system/permissions/#permission-levels","title":"Permission levels","text":"<p>The following table roughly defines the capabilities of each role</p> Group Capabilities logged in user Can do almost nothing without a group. guest - Search and view recipes- write comments - change user settings (e.g. language, theme, password) user Can do basically everything except for what admins can do admin - Create, edit and delete external storage- Create, edit and delete synced paths django superuser Ignores all permission checks and can access admin interface"},{"location":"system/permissions/#creating-user-accounts","title":"Creating User accounts","text":"<p>Warning</p> <p>Users without groups cannot do anything. Make sure to assign them a group!</p> <p>You can either create new users through the admin interface or by sending them invite links.</p> <p>Invite links can be generated on the System page. If you specify a username during the creation of the link  the person using it won't be able to change that name.</p>"},{"location":"system/permissions/#managing-permissions","title":"Managing Permissions","text":"<p>Management of permissions can currently only be achieved through the django admin interface.</p> <p>Warning</p> <p>Please do not rename the groups as this breaks the permission system.</p>"},{"location":"system/settings/","title":"Settings","text":"<p>Following is a description of the different settings for a space</p> <p>Warning</p> <p>Some settings and especially this page is work in Progress and the settings may behave differently the described here.</p>"},{"location":"system/settings/#use-plural-form","title":"Use Plural form","text":"<p>Default Value: <code>off</code></p> <p>This setting enables tandoor to display a plural form of a food or unit, if the plural version is entered for the food or unit. The plural version is displayed if the amount needed for a recipe is greater than 1 and will be adjusted to the current amount.</p> <p>In addition, this setting enables two new settings for an ingredient:</p> <ul> <li>Always show the plural version of the food: This will always display the plural version for a food, even if the amount is below or equal to 1. Requirement for this setting to activate is a plural version available in the database.</li> <li>Always show the plural version of the unit: This will always display the plural version for a unit, even if the amount is below or equal to 1. Requirement for this setting to activate is a plural version available in the database.</li> </ul> <p>Warning</p> <p>This setting is only meant to be a very simple version to enable some kind of pluralization for food and units. This feature may not meet your needs, but pluralization is a difficult topic and was discussed here.</p>"},{"location":"system/updating/","title":"Updating","text":"<p>The Updating process depends on your chosen method of installation</p> <p>While intermediate updates can be skipped when updating please make sure to  read the release notes in case some special action is required to update.</p>"},{"location":"system/updating/#docker","title":"Docker","text":"<p>For all setups using Docker the updating process look something like this</p> <ol> <li>Before updating it is recommended to create a backup!</li> <li>Stop the container using <code>docker-compose down</code></li> <li>Pull the latest image using <code>docker-compose pull</code></li> <li>Start the container again using <code>docker-compose up -d</code></li> </ol>"},{"location":"system/updating/#manual","title":"Manual","text":"<p>For all setups using a manual installation updates usually involve downloading the latest source code from GitHub. After that make sure to run:</p> <ol> <li><code>manage.py collectstatic</code></li> <li><code>manage.py migrate</code></li> </ol> <p>To apply all new migrations and collect new static files.</p>"}]}